[#ch14-synchronization]
:imagesdir: chapters/14-synchronization/images
:programsdir: chapters/14-synchronization/programs
== Sincronização

[quote, Mary Catherine Bateson]
____
Compartilhar é algumas vezes mais custoso do que dar.
____

=== Introdução

Os programas concorrentes permitem que várias threads sejam programadas e executadas,
mas o programador não tem muito controle sobre quando as threads são executadas. Conforme explicado em <<Conceitos: Agendamento de threads>>,
a JVM e o sistema operacional subjacente são responsáveis pelo agendamento de threads
nos núcleos do processador.

Ao escrever um programa concorrente, você precisa garantir que o programa
funcione corretamente, mesmo que diferentes execuções do mesmo programa
provavelmente levarão a diferentes sequências de execução de threads. O problema
que apresentaremos a seguir ilustra por que uma sequência de execução de thread pode ser
perfeitamente bem, enquanto outra pode levar a um comportamento inesperado e incorreto. (E até mesmo pessoas morrendo de fome!)

=== Problema: Jantar dos filósofos

A concorrente nos dá o potencial de tornar nossos programas mais rápidos, mas
introduz uma série de outros problemas. A maneira como as threads interagem pode
ser imprevisível. Como elas compartilham memória, uma thread pode corromper um valor
nas variáveis de outra thread. Apresentamos as ferramentas de sincronização
neste capítulo que podem evitar que os threads corrompam os dados, mas essas
ferramentas criam novas armadilhas. Para explorar essas armadilhas, apresentamos a você
outro problema para resolver.

Imagine vários filósofos sentados em uma mesa redonda com pratos
que são periodicamente preenchidos com arroz. Entre os filósofos adjacentes
estão pauzinhos individuais, de modo que há exatamente o mesmo número de
pauzinhos que o número de filósofos. Esses filósofos só pensam e
comem. Para comer, um filósofo deve pegar o pauzinho à
esquerdo e o da direita. <<figure-dining>> ilustra essa 
situação.

[[figure-dining]]
[.text-center]
.Mesa para cinco filósofos em um jantar.
image::diners.svg[scaledwidth=50%,pdfwidth=50%,width=50%]


Seu objetivo é escrever uma classe chamada `DiningPhilosopher` que estende
`Thread`. Cada thread criada no método `main()` deve ser um
filósofo que pensa por algum tempo aleatório, depois pega os dois pauzinhos necessários e come. Nenhum filósofo deve passar fome. Nenhum dos
filósofos deveria ficar preso indefinidamente brigando por pauzinhos.

Embora esse problema pareça simples, a solução não é.
Certifique-se de que você entendeu bem os conceitos e a sintaxe Java deste
capítulo completamente antes de tentar implementar sua solução. É importante que não haja dois filósofos tentando usar o mesmo pauzinho ao 
mesmo tempo. Da mesma forma, precisamos evitar uma situação em que cada
filósofo esteja esperando que todos os outros filósofos desistam de um
pauzinho.

=== Conceitos: Interação de thread

Esse problema do jantar dos filósofos destaca algumas dificuldades 
que estavam surgindo no final do último capítulo. Em
<<sharedThreadVariableExercise>> dois trechos de código poderiam ser executados
concorrentemente e modificar a mesma variável compartilhada, potencialmente produzindo uma
saída incorreta. Devido à natureza não determinística do agendamento,
temos de presumir que o código executado em duas ou mais threads pode ser
intercalados de qualquer maneira possível. Quando o *resultado* da computação
muda dependendo da ordem de execução da thread, ele é chamado de 
_condição de corrida_ (ou _race condition, em inglês). Abaixo está um 
exemplo simples de uma condição de corrida em Java.

.Exemplo simples de uma condição de corrida
[source, java]
[[RaceConditionProgram]]
----
include::{programsdir}/RaceCondition.java[]
----

Essa classe curta (e sem sentido) tenta incrementar a variável `counter` 
até que ela atinja `1000000`. Para ilustrar a condição de corrida,
dividimos o trabalho de incrementar `counter` igualmente entre vários
threads. Se você executar esse programa, o valor final de `counter
geralmente não será `1000000`. Dependendo de qual JVM, sistema operacional e quantos núcleos
você tem, talvez nunca obtenha `1000000`, e a resposta que você obtiver
variar muito. Em todos os sistemas, se você alterar o valor de `THREADS` 
para `1`, a resposta deverá estar sempre correta.

****
<<raceConditionExercise>> +
<<threadTimeSliceExercise>>
****

Observando o código, o problema pode não ser óbvio. Tudo
está centrado na instrução `counter{plus}{plus}` no loop `for` dentro 
método `run()`. Porém, essa instrução parece ser executada em uma única etapa!
Cada thread deve aumentar o valor de `counter` em um total de
`COUNT/THREADS` vezes, somando até `1000000`. O problema é que
`counter{plus}{plus}` *não* é uma única etapa. Lembre-se de que `counter{plus}{plus}` é uma abreviação 
para `contador = contador + 1`. Para ser ainda mais explícito, poderíamos escrever
da seguinte forma.

[source,java]
----
temp = counter;
counter = temp + 1;
----

Um thread pode chegar ao ponto de armazenar o `counter` em um local 
temporário, mas depois fica sem tempo, permitindo que a próxima thread 
agendada seja executada. Quando esse for o caso, a próxima thread poderá fazer uma série de
incrementos no `count` que são sobrescritos quando a primeira thread
for executada novamente. Como a primeira thread tinha um valor antigo de `counter`
armazenado em `temp`, adicionar 1 a `temp` tem o efeito de ignorar
os incrementos que ocorreram nesse intervalo. Essa situação pode ocorrer em um único 
processador com threads alternando entre si, mas é ainda mais perigosa
em um sistema com vários núcleos.

A principal lição aqui é que as threads podem alternar entre si a 
a qualquer momento, com efeitos imprevisíveis. A segunda lição é que o 
código-fonte é muito grosseiro para mostrar operações _atômicas_. Uma operação atômica
atômica é aquela que não pode ser interrompida por uma troca de contexto para
outra thread. O código real que a JVM executa é de nível muito mais baixo
do que o código-fonte.

Não é possível forçar facilmente uma operação não atômica a ser atômica, mas existem 
maneiras de restringir o acesso a determinadas partes do código sob certas
condições. O nome que damos a um trecho de código que não deve ser
acessado por mais de uma thread ao mesmo tempo é _seção crítica_. No
No exemplo acima, a única linha de código que incrementa o `counter` é 
uma seção crítica, e o erro no programa seria removido se
apenas uma thread pudesse executar essa linha de código por vez.

A proteção de uma seção crítica é feita com ferramentas de _exclusão mútua_.
Elas são chamadas de ferramentas de exclusão mútua porque impõem o
requisito de que uma thread que executa uma seção crítica exclui a
possibilidade de outra. Há muitas técnicas, algoritmos
e recursos de linguagem na ciência da computação que podem ser usados para criar
exclusão mútua. O Java depende muito de uma ferramenta chamada _monitor_ que
oculta do usuário alguns dos detalhes da aplicação da exclusão mútua.
A exclusão mútua é um tópico profundamente pesquisado com muitas abordagens além 
além dos monitores. Se planeja escrever programas concorrentes em outra
linguagem, talvez seja necessário se atualizar sobre os recursos de exclusão 
mútua dessa linguagem.

****
<<restaurantSynchronizationExercise>>
****

=== Sintaxe: Sincronização de thread

==== A palavra-chave `synchronized`

Em Java, o recurso de linguagem que permite que você aplique a 
exclusão mútua é a palavra-chave `synchronized`. Há duas maneiras de usar essa 
palavra-chave: com um método ou com um bloco arbitrário de código. No método
você adiciona o modificador `synchronized` antes do tipo de retorno.
Vamos imaginar uma classe com um campo `String` privado chamado `message`
que é definido como `“Will Robinson!”` pelo construtor. Agora, definimos
o seguinte método.

[source,java]
----
public synchronized void danger() {
    message = "Danger, " + message;
}
----

Se `danger()` for chamada cinco vezes em diferentes threads, `message` conterá +
`“Perigo, Perigo, Perigo, Perigo, Perigo, Will Robinson!”`. 
Sem a palavra-chave `synchronized`, `danger()` sofreria de uma condição de corrida
semelhante à de `RaceCondition`. Algumas das concatenações de `String`
podem ser sobrescritas por outras chamadas a `danger()`. 
Você nunca teria mais de cinco cópias de `“Danger,”` anexadas ao
no início de `message`, mas você pode ter menos.

****
<<synchronizedKeywordExercise>>
****

Sempre que uma thread entra em um trecho de código protegido pela palavra-chave 
`synchronized` ele adquire implicitamente um bloqueio que somente uma única thread pode
manter. Se outra thread tentar acessar o código, ela será forçada a esperar
até que o bloqueio seja liberado. Esse bloqueio é _reentrante_. Reentrante significa
significa que, quando uma thread mantém um bloqueio e tenta obtê-lo novamente, ela 
é bem-sucedida. Essa situação ocorre frequentemente com métodos sincronizados
que chamam outros métodos sincronizados.

****
<<lockTimingExercise>>
****

Considere o método `safety()` que faz o “`oposto`” de `danger()`, removendo 
as ocorrências de `“Danger,”` do início de `message`.

[source,java]
----
public synchronized void safety() {
    if(message.startsWith("Danger, "))
        message = message.substring(8);
}
----

Os métodos `danger()` e `safety()` funcionarão bem juntos no mesmo objeto? Em 
outras palavras, uma thread será impedida de entrar em
`safety()` se outra thread já estiver em `danger()`? Sim! Os bloqueios
em Java estão conectados a objetos. Quando você usa a palavra-chave `synchronized` em um método
o objeto no qual o método está sendo chamado (qualquer que seja o objeto
`this` se refere dentro do método) funciona como o bloqueio. Portanto, somente uma
thread pode estar dentro de qualquer um desses métodos em um determinado objeto. Se você tiver 10
métodos sincronizados em um objeto, somente um deles poderá ser executado por vez para esse objeto.


****
<<constructorLeakExercise>> +
<<synchronizedThreadIncrementExercise>>
****

Talvez esse nível de controle seja muito restritivo. Você pode ter seis
métodos que entram em conflito entre si e outros quatro que entram em conflito
entre si, mas não com os seis primeiros. Usar `synchronized` em cada 
declaração de método limitaria desnecessariamente a quantidade de 
concorrência que seu programa poderia ter.

Embora exija um pouco mais de trabalho, o uso de `synchronized` em um bloco
de código permite um controle mais refinado. A seguinte versão de
`danger()` é equivalente à anterior.


[source,java]
----
public void danger() {
    synchronized(this) {
        message = "Danger, " + message;
    }
}
----

O uso de `synchronized` em um bloco de código nos dá mais flexibilidade de duas 
maneiras. Primeiro, podemos escolher exatamente a quantidade de código que queremos controlar,
em vez de todo o método. Segundo, podemos escolher qual objeto queremos usar para 
a sincronização. No estilo de bloco, qualquer objeto arbitrário
pode ser usado como um bloqueio. Os objetos mantêm uma lista de threads que estão esperando
para obter o bloqueio e fazem todos os outros gerenciamentos necessários para que a palavra-chave
`synchronized` funcione.

Se houver duas seções críticas que não estejam relacionadas entre si, você
poderá usar o controle refinado que o estilo de bloco oferece. Primeiro, você precisará 
de alguns objetos para usar como bloqueios, provavelmente declarados de forma que possam ser
facilmente compartilhados, talvez como campos estáticos de uma classe.


[source,java]
----
private static Object lock1 = new Object();
private static Object lock2 = new Object();
----

Então, sempre que precisar de controle sobre a concorrência, use-os como bloqueios.

[source,java]
----
synchronized(lock1) {
    // Fazer coisas perigosas 1
}

// Fazer coisas seguras

synchronized(lock2) {
    // Fazer a coisa perigosa 2, não relacionada à coisa perigosa 1
}
----

Como declarar um método com `synchronized` é equivalente a ter seu corpo
em um bloco que começa com `synchronized(this)`, o que dizer dos métodos
métodos `static`? Eles podem ser `sincronizados`? Sim, podem. Sempre que uma classe
é carregada, o Java cria um objeto do tipo `Class` que
corresponde a essa classe. Esse objeto é o que os métodos estáticos sincronizados
dentro da classe usarão como bloqueio. Por exemplo, um método 
estático sincronizado dentro da classe `Eggplant` bloqueará o objeto
`Eggplant.class`.

==== Os métodos `wait()` e `notify()`

A proteção de seções críticas com a palavra-chave `synchronized` é uma
técnica poderosa, e muitas outras ferramentas de sincronização podem ser criadas
usando apenas essa ferramenta. Entretanto, a eficiência exige mais algumas opções.

Às vezes, uma thread está esperando que outra thread termine uma tarefa para
possa processar os resultados. Imagine uma thread coletando votos
enquanto outra está esperando para contá-los. Nesse exemplo, a thread de
contagem deve esperar que todos os votos sejam lançados antes de começar a
contar. Poderíamos usar um bloco sincronizado e um indicador `boolean`
chamado `votingComplete` para permitir que a thread do coletor sinalize para a thread de contagem.

[source,java]
----
while(true) {
    synchronized(this) {
        if(votingComplete)
            break;
    }
}
countVotes();
----

Qual é o problema com esse design? A thread de contagem está
está executando o loop `while` repetidamente, esperando que
`votingComplete` se torne `true`. Em um único processador, a thread de contagem
retardaria o trabalho da thread de coleta que está tentando processar todos os votos.
Em um sistema com vários núcleos, a thread de contagem
ainda está desperdiçando ciclos de CPU que alguma outra thread poderia usar. Esse
fenômeno é conhecido como _busy waiting_, por motivos óbvios.

Para combater esse problema, o Java fornece o método `wait()`. Quando uma 
thread está executando código sincronizado, ele pode chamar `wait()`. Em vez de ficar ocupada
esperando, uma thread que tenha chamado `wait()` será removida da lista de threads em execução.
Ele aguardará em um estado inativo até que alguém
apareça e notifique a thread de que sua espera terminou. Se você
lembrar do diagrama de estado da thread de <<ch13-concurrency#ch13-concurrency>>,
há um estado `Not Runnable` no qual as threads entram ao
chamar `sleep()`, chamando `wait()` ou executando E/S de bloqueio. Usando
`wait()`, podemos reescrever a thread de contagem de votos.

[source,java]
----
synchronized(this) {
    while(!votingComplete) {
        wait();
    }
}
countVotes();
----

Observe que o loop `while` foi movido para dentro do bloco sincronizado.
Fazer isso antes poderia ter impedido o término do nosso programa: 
Enquanto a thread de contagem de votos mantivesse o bloqueio, a thread de coleta de votos
não teria permissão para modificar `votingComplete`. Quando uma thread chama `wait()`,
no entanto, ele abre mão do bloqueio correspondente que está mantendo até que ela
acorde e execute novamente. Por que usar o loop `while` agora? Não há
garantia de que a condição que você está esperando é “verdadeira”. Muitas threads
podem estar esperando por esse bloqueio específico. Usamos o loop `while` para verificar
que `votingComplete` é `true` e esperamos *novamente* se não for.

Para notificar uma thread em espera, a outra thread chama o 
método `notify()`. Assim como o `wait()`, o `notify()` deve ser chamado em um
bloco ou método sincronizado. Aqui está o código correspondente que a thread de coleta de votos
pode usar para notificar a thread de contagem de votos de que a votação foi
concluída.

[source,java]
----
// Finish collecting votes
synchronized(this) {
    votingComplete = true;
    notifyAll();
}
----

Uma chamada a `notify()` despertará uma thread que esteja aguardando o objeto de bloqueio.
Se houver muitas threads aguardando, o método `notifyAll()` usado acima
pode ser chamado para despertar todas elas. Na prática, geralmente é mais seguro
chamar `notifyAll()`. Se uma determinada condição for alterada e uma única
thread em espera for notificada, essa thread talvez precise notificar a próxima
thread em espera quando tiver terminado. Se seu código não for *muito* 
cuidadosamente projetado, alguma thread pode acabar esperando para sempre e nunca ser notificada
se você depender apenas de `notify()`.

****
<<waitNotifyExercise>> +
<<notifyAllExercise>>
****

[[producerConsumerExample]]
.Produtor/consumidor
====

Para ilustrar o uso das chamadas `wait()` e `notify()` dentro do código 
sincronizado, apresentamos uma solução simples para o problema do produtor/consumidor
abaixo. Esse problema é um exemplo clássico no mundo da programação
concorrente. Muitas vezes, uma thread (ou um grupo de threads) está
produzindo dados, talvez de alguma operação de entrada. Ao mesmo tempo, uma
thread (ou, novamente, um grupo de threads) está pegando esses pedaços 
de dados e consumindo-os ao executar alguma tarefa computacional ou de saída.

Todo recurso dentro de um computador é finito. Produtor/consumidor
geralmente assumem um buffer limitado que armazena itens do 
produtor até que o consumidor possa retirá-los. Nossa solução faz toda a
sincronização nesse buffer. Muitas threads diferentes podem compartilhar esse
buffer, mas todos os acessos serão controlados.

.Exemplo de um buffer sincronizado.
[source, java]
[[BufferProgram]]
----
include::{programsdir}/Buffer.java[]
----
<.> Ao adicionar um item, os produtores entram no método sincronizado `addItem()` sincronizado.
<.> Se `count` mostrar que o buffer está cheio, o produtor deverá esperar
até que o buffer tenha pelo menos um espaço livre.
<.> Após adicionar um item ao
buffer, o produtor notifica todas as threads em espera.
<.> O consumidor
realiza operações espelhadas em `removeItem()`.
<.> Uma thread do consumidor não pode consumir nada se o buffer estiver vazio e deve, então, aguardar.
<.> Depois que houver
um objeto para consumir, o consumidor o remove e notifica todos as outras
threads.

Ambos os métodos são sincronizados, tornando o acesso ao buffer 
completamente sequencial. Embora pareça indesejável, o comportamento sequencial é
exatamente o que é necessário para o problema do produtor/consumidor. Todo
código sincronizado é uma proteção contra a concorrência insegura. O objetivo
é minimizar o tempo gasto no código sincronizado 
e fazer com que as threads voltem à execução paralela o mais rápido possível.
====

****
<<twoLockProducerConsumerExercise>>
****

[[bankAccountExample]]
.Conta bancária
====

Embora o produtor/consumidor seja um bom modelo para se ter em mente, existem 
outras maneiras pelas quais as threads de leitura e gravação podem interagir. Considere o
seguinte problema de programação, semelhante a um que você pode encontrar na vida real.

Como uma estrela em ascensão no departamento de TI de um banco, você recebeu a tarefa de
de criar uma nova classe de conta bancária chamada `SynchronizedAccount`. Essa 
classe deve ter métodos para suportar as seguintes operações: depósito,
saque e verificação de saldo. Cada método deve imprimir uma mensagem de status
na tela ao ser concluído. Além disso, o método para retirada deve retornar
`false` e não fazer nada se não houver fundos suficientes. Como o 
sistema mais recente é multi-threaded, esses métodos devem ser projetados de modo que
a contabilidade seja consistente, mesmo que muitas threads estejam acessando uma
uma única conta. Nenhum dinheiro deve aparecer ou desaparecer magicamente.

Há um desafio adicional. Para maximizar a concorrência,
`SynchronizedAccount` deve ser sincronizado de forma diferente para 
acessos de leitura e gravação. Qualquer número de threads deve ser capaz de
verificar o saldo de uma conta simultaneamente, mas somente uma thread pode
depositar ou sacar de cada vez.

Para resolver esse problema, nossa implementação da classe tem uma variável `balance`
para registrar o saldo, mas também tem uma variável `readers` para
manter o controle do número de threads que estão lendo da conta
em um determinado momento.

[source, java]
----
include::{programsdir}/SynchronizedAccount.java[lines=1..3]
----


Em seguida, o método `getBalance()` é chamado pelas threads que desejam ler o o saldo. 

[source, java]
----
include::{programsdir}/SynchronizedAccount.java[lines=5..16]
----
<.> O acesso à variável `readers` é sincronizado. 
<.> Depois de passar pelo primeiro bloco `sincronizado`, o código que armazena o
saldo não é mais sincronizado. Dessa forma, vários leitores podem acessar
os dados ao mesmo tempo. Para esse exemplo, os controles de concorrência que temos
são exagerados. O comando `amount = balance` não leva 
muito tempo. No entanto, se fosse assim, faria sentido para os leitores que 
o executassem de forma concorrente, como nós fazemos.
<.> Depois de ler o saldo, esse método
diminui `leitores`.
<.> Se `readers` chegar a 0, uma chamada para `notifyAll()` será realizada
sinalizando que as threads que estão tentando depositar ou retirar dinheiro da
conta podem continuar.

[source, java]
----
include::{programsdir}/SynchronizedAccount.java[lines=18..32]
----

Os métodos `deposit()` e `withdraw()` são invólucros para o 
método `changeBalance()`, que possui todos os controles de concorrência interessantes.

[source, java]
----
include::{programsdir}/SynchronizedAccount.java[lines=34..43]
----
<.> O método `changeBalance()` é sincronizado para que possa ter acesso 
exclusivo à variável `readers`. Ele também está marcado como `protected`
porque `SynchronizedAccount` será usado como uma super classe em
<<ch17-polymorphism#ch17-polymorphism>>.
<.> Enquanto `readers` for
for maior que 0, esse método aguardará.
<.> Eventualmente, os leitores devem
terminar seu trabalho e notificar o escritor em espera, que pode terminar de alterar o
o saldo da conta.
====

=== Armadilhas: Desafios de sincronização

Como você pode ver no problema do jantar dos filósofos, as ferramentas de sincronização
nos ajudam a obter a resposta correta, mas também criam outras dificuldades.

==== Impasse

Impasse (ou _Deadlock_) é a situação em que duas ou mais threads estão esperando
para que os outros sejam concluídos, para sempre. Alguma combinação de bloqueios ou outras
ferramentas de sincronização forçou uma dependência de bloqueio em um grupo de
thread que *nunca* será resolvida.

No passado, as pessoas descreveram quatro condições que devem existir para que o 
impasse aconteça.

.  Exclusão mútua: Apenas uma thread pode acessar o recurso (geralmente um
bloqueio) por vez.
.  Manter e esperar: uma thread que mantém um recurso pode solicitar recursos adicionais.
.  Sem preempção: Uma thread que mantém um recurso não pode ser forçada a 
liberá-lo por outra thread.
.  Espera circular: duas ou mais threads mantêm recursos que formam uma
cadeia circular de dependência.

[[deadlockPhilosophersExample]]
.Impasse dos filósofos
====

Ilustramos o impasse com um exemplo de como *não* resolver o problema dos 
filósofos. E se todos os filósofos decidissem pegar
o pauzinho à sua esquerda e depois o pauzinho à sua direita? Se o
momento fosse o ideal, cada filósofo estaria segurando um pauzinho
em sua mão esquerda e ficaria esperando eternamente que seu vizinho da direita
dê um pauzinho. Nenhum filósofo jamais conseguiria comer. Aqui está
esse cenário ilustrado em código.

[source, java]
----
include::{programsdir}/DeadlockPhilosopher.java[lines=1..8]
----
<.> Definimos uma constante para o número de assentos. 
<.> Criamos uma matriz `booleana` compartilhada chamada `chopsticks` para que todos os filósofos
possam saber quais pauzinhos estão sendo usados.
<.> O construtor atribui a cada filósofo um número de assento.


[source, java]
----
include::{programsdir}/DeadlockPhilosopher.java[lines=10..24]
----
<.> Em `main()`, criamos e iniciamos uma thread para cada 
filósofo.
<.> Em seguida, esperamos que eles terminem, o que, infelizmente, nunca acontecerá.


Depois de configurar a classe e o método `main()`, as coisas ficam interessantes
no método `run()`.

[source, java]
----
include::{programsdir}/DeadlockPhilosopher.java[lines=26..36]
----
<.> Primeiro, uma filósofa tenta pegar seu pauzinho esquerdo. 
<.> Em seguida, ela dorme por 50 milissegundos.
<.> Finalmente, ela tenta pegar seu pauzinho direito. Nós modificamos por `SEATS` para que o
último filósofo tente pegar o pauzinho no início da matriz. 

Sem o `sleep`, esse código normalmente funcionaria muito bem.
De vez em quando, os filósofos ficariam em um impasse, 
mas seria difícil prever quando. Ao introduzir o sleep, podemos praticamente
garantir que os filósofos sempre entrarão em um impasse.


Vale a pena examinar os dois métodos restantes para ver como a
sincronização é feita, mas ao obter os dois pauzinhos separadamente
acima, já nos metemos em problemas.

[source, java]
----
include::{programsdir}/DeadlockPhilosopher.java[lines=38..61]
----

====

[[deadlockSumExample]]
.Soma de impasses
====

Aqui está outro exemplo de impasse. Damos ênfase ao impasse porque ele é
um dos problemas mais comuns e problemáticos do uso da sincronização
de forma descuidada.

Considere duas threads que precisam acessar dois recursos separados.
Em nosso exemplo, os dois recursos são geradores de números aleatórios. 
O objetivo de cada uma dessas threads é adquirir bloqueios para os dois 
geradores de números aleatórios compartilhados, gerar dois números aleatórios cada e somar os números
gerados. (Observe que os bloqueios são totalmente desnecessários para esse problema
já que o acesso aos objetos `Random` é sincronizado).

[source, java]
----
include::{programsdir}/DeadlockSum.java[lines=1..7]
----


A classe começa criando objetos `static` `Random` compartilhados
`random1` e `random2` compartilhados. Em seguida, no método `main()`, a thread principal
gera duas novas threads, passando `true` para uma e `false` para a outra.

[source, java]
----
include::{programsdir}/DeadlockSum.java[lines=9..21]
----


Em seguida, a bagunça começa a se revelar. Uma das duas threads armazena
`true` em seu campo `reverse`.

[source, java]
----
include::{programsdir}/DeadlockSum.java[lines=23..25]
----


Por fim, temos o método `run()`, onde toda a ação acontece. Se as
duas threads em execução adquirissem bloqueios para `random1` e `random2` 
na mesma ordem, tudo funcionaria bem. Entretanto, a 
thread invertida bloqueia o `random2` e depois o `random1`, com um `sleep()` no meio.
entre eles. A thread não invertida tenta bloquear em `random1` e depois em
`random2`.

[source, java]
----
include::{programsdir}/DeadlockSum.java[lines=27..55]
----

Se você executar esse código, ele deverá invariavelmente causar um impasse com `thread1`
travado em `random2` e `thread2` travado em `random1`. Nenhum programador em sã 
consciência codificaria intencionalmente as threads dessa forma. De fato, o 
trabalho extra que fizemos para adquirir os bloqueios em ordens opostas 
é exatamente o que causa do impasse. Em programas mais complicados, pode haver
muitos tipos diferentes de threads e muitos recursos diferentes. Se duas
threads diferentes (talvez escritas por programadores diferentes) precisarem
recursos A e B ao mesmo tempo, mas tentarem adquiri-los 
na ordem inversa, esse tipo de impasse pode ocorrer sem uma causa óbvia.
causa óbvia.

Para esse tipo de impasse, a condição de espera circular pode ser quebrada
ordenando os recursos e sempre bloqueando os recursos em 
ordem crescente. Obviamente, essa solução só funciona se houver alguma maneira 
universal de ordenar os recursos e se a ordenação for sempre seguida por todas as
threads do programa.

Ignorando os problemas de impasse do exemplo acima, ele oferece um bom 
exemplo da maneira como o Java pretendia que a sincronização fosse feita: quando
possível, use o recurso de que você precisa como seu próprio bloqueio. Muitas outras
linguagens exigem que os programadores criem bloqueios ou semáforos adicionais
para proteger um determinado recurso, mas essa abordagem causa problemas se o 
mesmo bloqueio não for usado de forma consistente. Usar o próprio recurso como um bloqueio
é uma solução elegante.
====

****
<<deadlockExercise>>
****


==== Inanição e livelock

Inanição (ou _Starvation_) é outro problema que pode ocorrer com o uso descuidado de
ferramentas de sincronização. A inanição é um termo geral que abrange qualquer
situação em que alguma thread nunca obtém acesso aos recursos de que
precisa. O impasse pode ser visto como um caso especial de inanição, 
uma vez que nenhuma das threads que estão em impasse faz progresso.

O problema do jantar dos filósofos foi criado em torno da ideia de comer
com intenção humorística. Se um filósofo nunca conseguir adquirir
pauzinhos, esse filósofo literalmente morrerá de fome.

No entanto, a fome não significa necessariamente um impasse. Examine a 
implementação em <<bankAccountExample>> para a conta bancária.
Essa solução está correta no sentido de que preserva a 
exclusão mútua. Nenhuma combinação de verificações de saldo, depósitos ou retiradas
fará com que o saldo esteja incorreto. O dinheiro não será criado
nem destruído. Uma inspeção mais detalhada revela que a solução não é
totalmente justa. Se uma única thread estiver verificando o saldo, nenhuma outra
thread poderá fazer um depósito ou uma retirada. As threads de verificação de saldo
poderiam estar entrando e saindo constantemente, incrementando e decrementando a 
variável `readers`, mas se `readers` nunca chegar a zero, as threads
esperando para fazer depósitos e retiradas ficarão esperando para sempre.

****
<<concurrentReadExercise>>
****

Outro tipo de inanição é o _livelock_. No _deadlock_, dois ou mais
threads ficam presas e esperam para sempre, sem fazer nada. O _livelock_ é semelhante
exceto pelo fato de que as duas threads continuam executando o código e esperando por alguma
condição que nunca chega. Um exemplo clássico de _livelock_ são duas
pessoas educadas (mas estranhamente previsíveis) falando uma com a outra:
Ambas começam a falar exatamente no mesmo momento e depois param para ouvir o que a outra tem a dizer.
Depois de exatamente um segundo, as duas
começam novamente e param imediatamente. Ensaboar, enxaguar, repetir.

.Preparativos para a festa do _livelock_
====

Imagine três amigos indo a uma festa. Cada um deles começa a
a se arrumar em momentos diferentes. Eles seguem o padrão 
de se arrumar por um tempo, esperar que seus amigos se arrumem e
ligam para seus amigos para ver se os outros dois estão prontos. Se todos os três
estiverem prontos, os amigos irão embora. Infelizmente, se um amigo ligar
e um dos outros dois não estiver pronto, ele ficará frustrado e
e deixará de se arrumar. Talvez ele se dê conta de que tem tempo para 
tomar banho ou se envolver em alguma outra atividade por um tempo. 
Depois de terminar essa atividade, ele ficará pronto novamente e esperará que seus
amigos estejam prontos.

Se o momento for adequado, os três amigos continuarão se preparando,
esperando por um tempo e, em seguida, ficarão frustrados quando perceberem que
seus amigos não estão prontos. Aqui está uma simulação aproximada desse processo
em código.

[source, java]
----
include::{programsdir}/Livelock.java[lines=1..8]
----
<.> Primeiro, criamos uma variável compartilhada chamada `totalReady` que
rastreia o número total de amigos prontos.
<.> Para evitar condições de corrida, um `Object` compartilhado chamado `lock` será usado para controlar o
acesso ao `totalReady`. 
<.> Em seguida, o método `main()` cria objetos `Livelock`
representando cada um dos amigos.

[source, java]
----
include::{programsdir}/Livelock.java[lines=10..25]
----

O restante do método `main()` inicia cada uma das threads que representam
os amigos em execução, com um atraso de 100 milissegundos antes de a próxima thread
iniciar. Em seguida, ele espera que todos eles terminem. Se
for bem-sucedido, ele imprimirá `Tudo pronto!` na tela.

[source, java]
----
include::{programsdir}/Livelock.java[lines=27..49]
----
<.> No método `run()`, cada amigo passa por um loop até que a variável `done`
seja `verdadeiro`.
<.> Nesse loop, uma chamada inicial para `Thread.sleep()`
por 75 milissegundos representa a preparação para a festa.
<.> Depois disso,
`totalReady` é incrementado em um.
<.> Em seguida, o amigo espera por mais
75 milissegundos.
<.> Finalmente, ele verifica se todos os outros estão prontos
testando se o `totalReady` é `3`.
<.> Caso contrário, ele diminui o `totalReady` e repete o processo.

Aproximadamente 75 milissegundos após o início da simulação, o primeiro amigo fica
pronto, mas não verifica com seus amigos até 150 milissegundos.
Infelizmente, o segundo amigo não fica pronto até 175
milissegundos. Ele então verifica com seus amigos em 225 milissegundos,
momento em que o primeiro amigo está se preparando pela segunda vez.
No entanto, o terceiro amigo não está pronto até 275 milissegundos. 
Quando ele faz a verificação em 350 milissegundos, o primeiro amigo não está mais pronto.
Em alguns sistemas, o tempo pode variar de forma que todos os amigos fiquem
prontos ao mesmo tempo, mas isso pode levar muito, muito tempo.

Na realidade, os seres humanos não adiariam a ida a uma festa
indefinidamente. Algumas pessoas decidiriam que já era tarde demais para ir.
Outras iriam sozinhas. Outras iriam até a casa de seus 
amigos e exigiriam saber por que estava demorando tanto. Os computadores não são tão
sensíveis e devem obedecer às instruções, mesmo que elas causem 
padrões repetitivos inúteis. Exemplos realistas de _livelock_ são difíceis de mostrar em
em um pequeno trecho de código, mas eles aparecem em sistemas reais e podem ser
muito difíceis de prever.

====

==== Execução sequencial

Ao projetar um programa paralelo, você pode perceber que as ferramentas de sincronização
são necessárias para obter uma resposta correta. Então, quando você executa essa
versão paralela e a compara com a versão sequencial, ela não é executada
mais rápido ou, pior ainda, é executada mais lento do que a versão sequencial. O excesso de zelo
com as ferramentas de sincronização pode produzir um programa que dá a 
resposta correta, mas que não explora nenhum paralelismo.

Por exemplo, podemos usar o método `run()` 
da implementação paralela da multiplicação de matrizes fornecida em <<matrixMultiplicationExample>>
e usar a palavra-chave `synchronized` para bloquear a própria matriz.

[source,java]
----
public void run() {
    synchronized(c) {
        for(int i = lower; i < upper; i++)
            for(int j = 0; j < c[i].length; j++)
                for(int k = 0; k < b.length; k++)
                    c[i][j] += a[i][k] * b[k][j];
    }
}
----

Nesse caso, apenas uma thread teria acesso à matriz 
a qualquer momento, e todo o aumento de velocidade seria perdido.

Para a versão paralela da multiplicação de matrizes que apresentamos 
anteriormente, nenhuma sincronização é necessária. 
No caso do problema do produtor/consumidor, a sincronização é necessária,
e a única maneira de gerenciar o buffer adequadamente é impor a execução 
sequencial. Às vezes, a execução sequencial não pode ser evitada, mas você
sempre deve saber quais partes do código estão realmente sendo executadas 
em paralelo e quais não estão, se quiser obter o máximo de aceleração. 
A palavra-chave `synchronized` deve ser usada sempre que for 
necessária, mas não mais do que isso.

==== Inversão de prioridade

No <<ch13-concurrency#ch13-concurrency>>, sugerimos que você raramente use
prioridades de thread. 
Mesmo os bons motivos para usar prioridades podem ser frustrados pela 
_inversão de prioridade_. Na inversão de prioridade, uma thread de 
prioridade mais baixa mantém um bloqueio necessário para uma thread 
de prioridade mais alta, potencialmente por um longo tempo. Como a 
thread de alta prioridade não pode continuar, a thread de prioridade 
mais baixa obtém mais tempo de CPU, como se fosse uma thread de alta prioridade.

Pior ainda, se houver algumas threads de prioridade média no sistema, a 
thread de baixa prioridade poderá manter o bloqueio necessário para a thread de alta prioridade por
ainda mais tempo, porque essas threads de prioridade média reduzem a quantidade de
tempo de CPU que a thread de baixa prioridade tem para concluir sua tarefa.

****
<<priorityInversionExercise>> +
<<priorityiInversionExperimentExercise>>
****

=== Solução: Jantar dos filósofos

Aqui apresentamos nossa solução para o problema do jantar dos filósofos. Embora o
o impasse fosse a principal armadilha que estávamos tentando evitar, muitas outras questões
podem surgir em soluções para esse problema. Um único filósofo pode ser forçado a passar fome, ou todos os filósofos podem passar por um _livelock_ por meio de um padrão de pegar e largar os pauzinhos que
nunca dá certo. Uma solução muito simples poderia permitir que os filósofos comessem, um a um, em ordem. Então, os filósofos
desnecessariamente e com frequência estariam esperando para comer, e o programa
se aproximaria da execução sequencial.

O principal elemento que faz com que nossa solução funcione é o fato de forçarmos um
filósofo a pegar dois pauzinhos atomicamente. O filósofo irá
pegará os dois pauzinhos ou não pegará nenhum.

[source, java]
----
include::{programsdir}/DiningPhilosopher.java[lines=1..10]
----

Começamos com uma configuração semelhante à versão de impasse apresentada em
<<deadlockPhilosophersExample>>.

[source, java]
----
include::{programsdir}/DiningPhilosopher.java[lines=12..26]
----
<.> Em `main()`, criamos e iniciamos uma thread para cada
filósofo.
<.> Em seguida, esperamos que eles terminem.


[source, java]
----
include::{programsdir}/DiningPhilosopher.java[lines=28..44]
----
<.> Esse método `run()` é diferente da versão com deadlock, mas não de
uma maneira que impeça o impasse.
<.> Adicionamos o loop `for` para que você pudesse
ver os filósofos comerem e pensarem muitas vezes diferentes sem
problemas.
<.> Também adicionamos o método `think()` para randomizar a quantidade de
tempo entre as refeições, para que cada execução do programa seja menos
determinística.


[source, java]
----
include::{programsdir}/DiningPhilosopher.java[lines=46..63]
----
<.> O verdadeiro local onde o deadlock é evitado é no método `getChopsticks()`. 
Como no <<deadlockPhilosophersExample>>, modificamos por `SEATS` para que o último filósofo
tente obter o primeiro pauzinho da matriz.
<.> O filósofo pega `chopsticks` e bloqueia.
<.> Em seguida, ela pega os dois pauzinhos de que precisa somente se ambos estiverem disponíveis.
<.> Caso contrário, ele espera.

[source, java]
----
include::{programsdir}/DiningPhilosopher.java[lines=65..76]
----
<.> Finalmente, no método `eat()`, o filósofo come o arroz. Nós
podemos presumir que algum outro cálculo seria feito aqui em um problema 
realista *antes* de entrar no bloco `synchronized`. O ato de comer em si
não requer um bloqueio.
<.> Depois que a refeição termina, o bloqueio é adquirido para
devolver os pauzinhos (esperamos que depois de alguma limpeza). 
<.> Em seguida, todos os filósofos em espera são notificados de que alguns pauzinhos podem ter se tornado
disponíveis.

Nossa solução evita o _deadlock_ e o _livelock_ porque *algum* filósofo
acabará obtendo o controle de dois pauzinhos, mas ainda há
problemas. Observe que cada filósofo come e pensa apenas 100 vezes. Se,
em vez de filósofos compartilhando pauzinhos, cada thread fosse um servidor
compartilhando unidades de armazenamento de rede, o programa poderia ser executado por um
tempo não especificado: dias, semanas e até anos. Se a fome estiver acontecendo com um
filósofo específico em nosso programa, os outros filósofos
terminarão após 100 rodadas, e o filósofo faminto poderá recuperar o atraso. Se
não houvesse nenhuma limitação no loop, um filósofo faminto poderia nunca
recuperar o atraso.

Mesmo se aumentarmos bastante o número de iterações do loop,
provavelmente não veríamos a inanição de uma thread individual porque estamos
trapaceando de outra forma. Uma sequência azarada de acessos ao pauzinho
por dois filósofos vizinhos poderia fazer com que o filósofo entre
entre eles fique com fome. Ao fazer com que o método `think()` espere um período 
de tempo aleatório, essa sequência provavelmente será interrompida.
Se todos os filósofos pensassem por
exatamente a mesma quantidade de tempo em cada turno, um padrão de azar poderia se 
repetir. Não é irracional acreditar que a quantidade 
de pensamento que um filósofo (ou um servidor) fará em um determinado momento
varia, mas o comportamento depende do sistema.

É muito difícil encontrar uma resposta perfeita para alguns
problemas de sincronização. Esses problemas vêm sendo estudados há muitos
anos, e as pesquisas continuam para encontrar soluções melhores.

****
<<fairDiningPhilosophersExercise>>
****

=== Exercícios
*Problemas conceituais*

.  [[synchronizedKeywordExercise]] Qual é a finalidade da palavra-chave
`synchronized`? Como ela funciona?
.  [[constructorLeakExercise]] A especificação de linguagem para Java
torna ilegal o uso da palavra-chave `synchronized` em construtores.
Durante a criação de um objeto, é possível _vazar_ dados para o 
mundo externo adicionando uma referência ao objeto em construção a
alguma estrutura de dados compartilhada. Qual é o perigo de vazar dados dessa forma?
dessa forma?
.  [[waitNotifyExercise]] Se você chamar
`wait()` ou `notify()` em um objeto, isso *deve* estar dentro de um bloco
sincronizado no mesmo objeto. Caso contrário, o código será compilado, mas uma mensagem
`IllegalMonitorStateException` poderá ser lançada em tempo de execução. Por que é
necessário possuir o bloqueio em um objeto antes de chamar `wait()` ou
`notify()` sobre ele?
.  [[notifyAllExercise]] Por que é mais seguro chamar
`notifyAll()` do que `notify()`? Se geralmente é mais seguro chamar
`notifyAll()`, há algum cenário em que há boas razões para chamar `notify()`?
.  [[restaurantSynchronizationExercise]] Imagine uma simulação de um 
restaurante com muitos objetos de garçom e chef. Os garçons devem enviar 
pedidos à equipe da cozinha, e os chefs devem dividir o trabalho 
entre si. Como você projetaria esse sistema? Como as informações e os
alimentos seriam passados do garçom para o chef e do chef para o garçom? Como você
sincronizaria o processo?
.  [[raceConditionExercise]] O que é uma condição de corrida? Dê um 
exemplo real de uma.
.  [[synchronizedThreadIncrementExercise]] Vamos reexaminar o código que
incrementa uma variável com várias threads de
<<Conceitos: Interação de thread>>. Podemos reescrever o método `run()`
da seguinte forma.
+
[source,java]
----
public synchronized void run() {
    for(int i = 0; i < COUNT/THREADS; i++)
        counter++;
}
----
+
Essa alteração corrigirá a condição de corrida? Por que sim ou por que não?
.  [[deadlockExercise]] Examine nosso exemplo de impasse 
em <<deadlockSumExample>>. Explique por que esse exemplo atende a todas as
quatro condições de impasse. Seja específico com relação a quais threads e quais
recursos são necessários para demonstrar cada condição.
.  [[priorityInversionExercise]] O que é inversão de prioridade? Por que
uma thread de baixa prioridade com um bloqueio pode ser particularmente problemática?

*Práticas de programação*

. [[twoLockProducerConsumerExercise]] Em
<<producerConsumerExample>> a classe `Buffer` usada para
implementar uma solução para o problema do produtor/consumidor tem apenas um 
único bloqueio. Quando o buffer está vazio e um produtor coloca um item nele, ambos
produtores e consumidores são acordados. Uma situação semelhante acontece
sempre que o buffer está cheio e um consumidor remove um item. Reimplementar
essa solução com dois bloqueios, de modo que um produtor que coloca um item em um
buffer vazio só desperte os consumidores e que um consumidor que remova um item
de um buffer cheio só desperte os produtores.
. [[concurrentReadExercise]] Em <<bankAccountExample>>
usamos a classe `SynchronizedAccount` para resolver um problema de conta bancária.
Como mencionamos em <<Inanição e livelock>>, as threads de depósito
e retiradas podem ser eliminadas por um suprimento constante de 
threads de verificação de saldo. Adicione ferramentas de sincronização adicionais a
`SynchronizedAccount` para que as threads de verificação de saldo se revezem
com as threads de depósito e retirada. Se não houver threads 
de depósito ou retirada, faça com que sua implementação continue a permitir um
número ilimitado de threads de verificação de saldo para leitura concorrente.
. [[fairDiningPhilosophersExercise]] A solução para o problema do jantar dos
filósofos dada em <<Solução: Jantar dos filósofos>> sofre com o 
problema de que um filósofo pode ficar faminto pelos dois 
filósofos de cada lado dela, se ela não tiver sorte. Adicione
variáveis a cada filósofo que indicam fome e a última vez que um 
filósofo comeu. Se um determinado filósofo estiver com fome e não tiver comido
há mais tempo que seu vizinho, ele não deverá pegar o
pauzinho que eles compartilham. Adicione ferramentas de sincronização para aplicar esse
princípio de justiça. Observe que sua solução não deve causar
impasse. Embora um filósofo possa estar esperando por outro, que está esperando por 
outro e assim por diante, *algum* filósofo no círculo deve ter o mesmo tempo de espera 
ter ficado com fome por mais tempo, quebrando o tempo de espera.

*Experimentos*

. [[lockTimingExercise]] As seções críticas podem tornar o programa mais lento
ao impedir a computação paralela. No entanto, os bloqueios usados para reforçar as seções críticas podem adicionar atrasos extras além disso. Projete
um experimento simples que adquire repetidamente um bloqueio e faz alguma
operação simples. Teste o tempo de execução com e sem o bloqueio. Veja
se você pode estimar o tempo necessário para adquirir um bloqueio em Java em seu
sistema.
. [[threadTimeSliceExercise]] Desenhe um programa que
determina experimentalmente quanto tempo uma thread está programada para passar
em execução numa CPU antes de passar para a próxima thread. Para fazer isso, primeiro
crie um loop fechado que execute um grande número de iterações, talvez
1.000.000 ou mais. Determine quanto tempo leva para executar uma única execução
dessas iterações. Em seguida, escreva um laço externo que execute o laço fechado
várias vezes. A cada iteração do laço externo, teste para ver quanto tempo
tempo passou. Quando encontrar um grande salto no tempo, tipicamente
pelo menos 10 vezes a quantidade de tempo que o loop fechado normalmente leva para ser executado até a 
conclusão, registe esse tempo. Se você executar esses loops em várias threads
e calcular a média dos tempos incomumente longos para cada thread, você
deve ser capaz de descobrir quanto tempo cada thread espera entre
execuções. Usando essa informação, você pode estimar quanto tempo cada thread
está alocada. Tenha em mente que essa média é apenas uma estimativa. Algumas JVMs
alteram a quantidade de tempo de CPU alocada às threads por várias
razões. Se você estiver em uma máquina com vários núcleos, será mais difícil
interpretar seus dados, pois algumas threads estarão sendo executadas concorrentemente.
. [[priorityiInversionExperimentExercise]] Criar um experimento para
investigar a inversão de prioridades da seguinte forma.
..  Crie duas threads, definindo a prioridade da primeira como
`MIN_PRIORITY` e a prioridade da segunda para `MAX_PRIORITY`. Iniciar
a primeira thread em execução, mas espere 100 milissegundos antes de iniciar a
segunda thread. A primeira thread deve adquirir um bloqueio compartilhado e então
executar algum processo demorado, como encontrar a soma dos senos do
primeiro milhão de inteiros. Depois de terminar o cálculo, ela deve
liberar o bloqueio e imprimir uma mensagem. A segunda thread deve tentar 
adquirir o bloqueio, imprimir uma mensagem e, em seguida, liberar o bloqueio. Cronometre o 
processo. Como o bloqueio é mantido pela thread de prioridade mais baixa, a thread de
prioridade mais alta terá que esperar até que a outra thread termine
para que ela termine.
..  Quando tiver uma ideia do tempo que leva 
para que essas duas threads terminem sozinhas, crie mais 10 threads que também devem realizar uma série de 
computação. No entanto, não faça com que essas threads tentem adquirir o bloqueio. 
Quanto é que elas atrasam a conclusão da tarefa? Como é que este atraso se relaciona com
o número de núcleos do seu processador? Quanto o atraso muda se
você definir as prioridades dessas novas threads como `MAX_PRIORITY` ou
`MIN_PRIORITY`?

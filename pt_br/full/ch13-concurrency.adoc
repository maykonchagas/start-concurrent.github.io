:xrefstyle: short
:chapter-caption: Capítulo

[#ch13-concurrency]
:imagesdir: chapters/13-concurrency/images
:programsdir: chapters/13-concurrency/programs
== Programação Concorrente

[quote, Jorge Luis Borges]
____
O tempo é a substância da qual sou feito. O tempo é um rio que me arrasta, mas 
eu sou o rio; é um tigre que me devora, mas eu sou o tigre; é um fogo que me 
consome, mas eu sou o fogo.
____

=== Introdução

Até agora, nos concentramos principalmente em escrever programas sequenciais. A 
execução sequencial significa que as instruções do programa são executadas uma 
de cada vez em uma sequência determinada pela lógica do programa e pelos dados 
de entrada. No entanto, mais de uma instrução de programa pode ser executada 
independentemente por um processador multicore. Embora seja comum os programadores 
escreverem programas sequenciais, a disponibilidade generalizada de processadores 
de vários núcleos em um único computador levou a um aumento na demanda por 
programadores que possam escrever programas concorrentes.

Um programa concorrente é aquele em que várias instruções podem ser executadas 
simultaneamente por dois ou mais núcleos. Neste capítulo, mostramos como escrever 
programas concorrentes simples em Java que exploram o poder de um computador com 
vários núcleos. Começamos com um problema em que o destino do planeta está em 
grave perigo!

=== Problema: Vírus mortal

Um vírus mortal capaz de exterminar a população mundial está prestes a ser liberado 
por um gênio do mal. Somente ele sabe o código de segurança que pode interromper a 
contagem regressiva.  O mundo está condenado. A única esperança de salvação está em 
você e em suas habilidades de programação em Java. Por meio das investigações de uma 
rede de espionagem ultrassecreta e financiada pelo governo, foi revelado que o código 
de segurança está vinculado ao número 59.984.005.171.248.659. Esse grande número é 
o produto de dois números primos, e o código de segurança é a soma deles. Tudo o que 
você precisa fazer é fatorar o número 59.984.005.171.248.659 em seus dois fatores 
primos e somá-los.

É claro que há uma pegadinha.  O vírus mortal será lançado em breve, tão em breve que 
talvez não haja tempo suficiente para seu computador pesquisar todos os números um a 
um. Em vez disso, você deve usar a concorrência para verificar mais de um número por vez.

Esse problema parece artificial?  Para manter a privacidade das informações enviadas 
pela Internet, muitos tipos de criptografia de chave pública dependem da dificuldade 
de fatorar números grandes. Embora a fatoração do número nesse problema não seja 
difícil, os números usados para criptografia de chave pública, geralmente com mais de 
300 dígitos decimais, resistem à fatoração até mesmo pelos computadores mais rápidos.

=== Conceitos: Dividindo para conquistar

O problema do vírus mortal tem uma grande tarefa (fatorar um número) a ser executada. 
Como devemos dividir essa tarefa para que possamos realizá-la mais rapidamente? Dividir 
o trabalho a ser feito é o cerne de qualquer solução simultânea para um problema.

Em um processador com vários núcleos, cada núcleo é um trabalhador independente. É 
preciso algum cuidado para coordenar esses trabalhadores. Antes de tudo, ainda precisamos 
obter a resposta correta. Uma solução concorrente não tem valor se estiver incorreta 
e, ao ler e gravar na mesma memória compartilhada, as respostas encontradas por um 
núcleo podem corromper as respostas encontradas por outros núcleos. A prevenção desse 
problema será abordada no <<ch14-synchronization#ch14-synchronization>>. Quando pudermos 
garantir que a solução concorrente está correta, também vamos querer melhorar o desempenho. 
Talvez queiramos que a tarefa seja concluída mais rapidamente. Talvez tenhamos um sistema 
interativo que deva continuar a lidar com as solicitações dos usuários mesmo que esteja 
trabalhando em uma solução em segundo plano. Novamente, se a sobrecarga de coordenar nossos 
trabalhadores levar mais tempo do que uma solução sequencial ou tornar o sistema menos 
responsivo, isso não será útil.


****
<<sharedThreadVariableExercise>>
****

Há duas maneiras principais de dividir o trabalho. A primeira é chamada de _decomposição 
de tarefas_. Nessa abordagem, cada funcionário recebe uma tarefa diferente para fazer. A 
segunda é chamada de _decomposição de domínio_. Nessa abordagem, os funcionários fazem o 
mesmo trabalho, mas com dados diferentes.

É possível usar tanto a decomposição de tarefas quanto a de domínios para resolver o mesmo 
problema. Com os dois tipos de decomposição, geralmente é necessário coordenar os 
trabalhadores para que possam compartilhar informações. Nas próximas duas subseções, 
descreveremos com mais detalhes a decomposição de tarefas e a decomposição de domínios. 
Em seguida, discutiremos o mapeamento de tarefas para _threads_ de execução e as diferentes 
arquiteturas de memória que podem ser usadas para programação simultânea.

==== Decomposição de tarefas 

A ideia de dividir uma tarefa em subtarefas menores é natural. Imagine que você está 
planejando um jantar. Você precisa comprar suprimentos, preparar o jantar, limpar a casa 
e arrumar a mesa. Se quatro de vocês estivessem planejando a festa, cada um poderia 
realizar uma atividade separada. Os preparativos poderiam ser muito mais rápidos do que 
se uma única pessoa estivesse fazendo o trabalho, mas a coordenação ainda é importante. 
Talvez a pessoa que estiver preparando o jantar não possa terminar até que certos 
suprimentos sejam comprados.

A decomposição de tarefas geralmente é mais fácil do que a decomposição de domínios porque 
muitas tarefas têm divisões naturais. Infelizmente, essa nem sempre é uma maneira eficaz de 
usar vários núcleos em um computador. Se uma tarefa for concluída muito antes das outras, 
um núcleo poderá ficar ocioso.

****
<<minimumTimeForTasksExercise>>
****

Os dois exemplos a seguir mostram ilustrações simples do processo de divisão de uma tarefa em subtarefas menores no contexto da programação multicore.

[[videoGameTasksExample]]
.Tarefas de videogame
====

Considere um videogame simples que consiste nas seguintes tarefas

.  Iniciar o jogo 
.  Processar a jogada
.  Atualizar pontuação
.  Repintar a tela
.  Encerrar o jogo

[[figure-video_game_tasks]]
[.text-center]
.Execução de tarefas em um vídeogame. (a) Execução sequencial em um núcleo. (b) Execução concorrente em dois núcleos. As setas indicam o fluxo de execução e de transferência de dados.
image::video-game-tasks.svg[label="Figura",caption="Figura ",scaledwidth=75%,pdfwidth=75%,width=75%]

Suponha que as tarefas B e D sejam independentes e possam ser executadas simultaneamente se houver dois núcleos disponíveis. A tarefa D atualiza continuamente a tela com os dados antigos até que a tarefa C atualize as informações.

<<figure-video_game_tasks>>(a) e (b) mostram como as tarefas desse videogame podem ser sequenciadas, respectivamente, em um único núcleo ou em dois núcleos. Todas as tarefas são executadas sequencialmente em um processador de núcleo único. Em um processador de núcleo duplo, as tarefas B e C podem ser executadas em um núcleo enquanto a tarefa D é executada simultaneamente em outro. Observe na figura que a tarefa C envia a pontuação e qualquer outros dados para a tarefa D, que atualiza continuamente a tela. Ter dois núcleos pode permitir uma atualização mais rápida da tela, pois o processador não precisa esperar que as tarefas B ou C sejam concluídas.


====

[[mathExpressionTasksExample]]
.Tarefas de expressão matemática
====

Suponha que precisemos avaliar a expressão matemática 2__Kate__^-{wj}__at__²^ com os parâmetros _a_ e _K_ em um determinado valor de _t_. Podemos dividir a expressão em dois termos: 2__Kat__ e _e_^-{wj}__at__²^. Cada um desses termos pode ser atribuído a uma tarefa diferente para avaliação. Em um processador de dois núcleos, essas duas tarefas podem ser executadas em núcleos separados e os resultados de cada uma delas podem ser combinados para encontrar o valor da expressão para a tarefa principal.


[[figure-math_evaluation]]
[.text-center]
.Avaliação de uma expressão matemática (a) sequencialmente em um único núcleo e (b) simultaneamente em dois núcleos. As setas mostram o fluxo de execução e a transferência de dados. A fonte em destaque indica a operação que está sendo executada.
image::mathematical-expression-evaluation.svg[scaledwidth=75%,pdfwidth=75%,width=75%]


<<figure-math_evaluation>> mostra como essa expressão pode ser avaliada em processadores de um núcleo e de dois núcleos. Às vezes, o uso de vários núcleos para avaliar uma expressão como essa levará menos tempo do que um único núcleo. No entanto, não há garantia de que o uso de vários núcleos sempre será mais rápido, pois as tarefas levam tempo para serem configuradas e para se comunicarem entre si.
====

****
<<mathExpressionTimingExercise>> +
<<quad-coreExercise>>
****

Esses exemplos ilustram como uma tarefa pode ser dividida em duas ou mais subtarefas executadas por diferentes núcleos de um processador. Usamos um processador dual-core em nossos exemplos, mas as mesmas ideias podem ser expandidas para um número maior de núcleos.

==== Decomposição de domínio

Em um programa de computador, cada tarefa executa operações em dados. Esses dados são chamados de _domínio_ dessa tarefa. Na decomposição do domínio, os dados são divididos em partes menores, em que cada parte é atribuída a um núcleo diferente, em vez de dividir uma tarefa em subtarefas. Assim, cada núcleo executa a mesma tarefa, mas em dados diferentes.

No exemplo do jantar, poderíamos ter usado a decomposição de domínio em vez de (ou além de) decomposição de tarefa. Se quiser cozinhar uma grande quantidade de purê de batatas, você mesmo pode descascar 24 batatas. Entretanto, se houver quatro pessoas (e cada uma delas tiver um descascador de batatas), cada pessoa precisará descascar apenas 6 batatas.

A estratégia de decomposição de domínio é muito útil e é um dos principais focos da simultaneidade neste livro. Os problemas da computação moderna geralmente usam dados maciços, que incluem milhões de valores ou milhares de registros de bancos de dados. Escrever programas que possam dividir os dados de modo que vários núcleos possam processar seções menores pode acelerar muito o tempo necessário para concluir o cálculo.

De certa forma, a decomposição de domínios pode ser mais difícil do que a decomposição de tarefas. Os dados devem ser divididos de maneira uniforme e justa. Depois que cada seção de dados tiver sido processada, os resultados deverão ser combinados. Empresas como o Google, que processam grandes quantidades de informações, desenvolveram uma terminologia para descrever esse processo. Dividir os dados e atribuí-los aos funcionários é chamado de etapa do mapa (_map_). A combinação das respostas parciais na resposta final é chamada de etapa de redução (_reduce_).

Ilustramos a estratégia de decomposição de domínio nos dois exemplos a seguir.

[[arraySummationPreviewExample]]
.Visualização da soma de matrizes
====

Suponha que queiramos aplicar a função _f_ a cada elemento
de uma matriz _a_ e somar os resultados. Matematicamente, queremos calcular a seguinte soma.

//[stem]
//++++
//S = \sum_{i=1}^N f\left(a_i\right)
//++++

[.text-center]
image::oneCoreSum.svg[scaledwidth=15%,pdfwidth=15%,width=15%]



Nessa fórmula, _a_~_i_~ é o _i_^ésimo^ elemento da matriz _a_. Vamos supor que temos um processador dual-core disponível para calcular a soma. Dividimos a matriz de modo que cada núcleo execute a tarefa em metade da matriz. Sejam _S_~1~ e _S_~2~ denotem as somas calculadas pelo núcleo 1 e pelo núcleo 2, respectivamente.

//[stem]
//++++
//S_1 = \sum_{i=1}^{\lfloor \frac{N}{2}\rfloor } f\left(a_i\right)\hspace{.75in}
//S_2 = \sum_{i=\lfloor \frac{N}{2} \rfloor +1}^{N} f\left(a_i\right)
//++++

[.text-center]
image::twoCoreSum.svg[scaledwidth=50%,pdfwidth=50%,width=50%]


Supondo que _N_ seja uniforme, os dois núcleos processam exatamente a
mesma quantidade de dados. Para _N_ ímpar, um dos núcleos processa
um item de dados a mais do que o outro.

[[figure-array_decomposition]]
[.text-center]
.Calculando a soma de uma função de cada elemento de uma matriz.
image::arrayDecomposition.svg[scaledwidth=60%,pdfwidth=60%,width=60%]

Depois que _S_~1~ e _S_~2~ tiverem sido computados, um dos
núcleos pode somar esses dois números para obter _S_.
Essa estratégia é ilustrada em <<figure-array_decomposition>>.
Depois que os dois núcleos tiverem concluído seu trabalho em cada metade da matriz,
as somas individuais são então somadas para produzir o resultado final.
====

[[matrixMultiplicationPreviewExample]]
.Visualização da multiplicação de matrizes
====

A necessidade de multiplicar matrizes surge em muitas aplicações matemáticas, científicas e de engenharia. Suponha que nos peçam para escrever um programa para
multiplicar duas matrizes quadradas _A_ e _B_, que
são ambas matrizes _n_ × _n_. A matriz do produto
_C_ também será _n_ × _n_. Um programa
sequencial calculará cada elemento da matriz _C_ um de cada vez.
vez. Entretanto, um programa simultâneo pode calcular mais de um elemento de
_C_ simultaneamente usando vários núcleos.

[[figure-matrix_decomposition]]
[.text-center]
.Decomposição de dados para multiplicar duas matrizes 4 × 4. Os dois núcleos executam as mesmas tarefas de multiplicação, mas em dados diferentes da matriz _A_.Os dois núcleos calculam as duas linhas superiores e as duas linhas inferiores de _C_, respectivamente.
image::matrixDecomposition.svg[scaledwidth=75%,pdfwidth=75%,width=75%]


Neste problema, a tarefa é multiplicar as matrizes _A_ e
_B_. Por meio da decomposição de domínio, podemos replicar essa
tarefa em cada núcleo. Conforme mostrado na <<figure-matrix_decomposition>>,
cada núcleo calcula apenas uma parte de _C_. Por exemplo, se
_A_ e _B_ forem 4 × 4, podemos pedir a um núcleo que calcule o produto das duas primeiras
linhas de _A_ com todas as quatro colunas de _B_ para
gerar as duas primeiras linhas de _C_. O segundo núcleo calcula
as duas linhas restantes de _C_. Ambos os núcleos podem acessar as
matrizes _A_ e _B_.

====

==== Tarefas e threads

É responsabilidade do programador dividir sua solução em
uma série de tarefas e subtarefas que serão executadas em um ou mais núcleos de um
processador. Nas seções anteriores, descrevemos programas concorrentes como se
tarefas específicas pudessem ser atribuídas a núcleos específicos, mas o Java não
fornece uma maneira direta de fazer isso.

Em vez disso, um programador Java deve agrupar um conjunto de tarefas e
subtarefas em uma _thread_. Uma thread é muito parecido com um programa
sequencial. De fato, todos os programas sequenciais são compostos de uma única thread.
Uma thread é um segmento de execução de código que percorre suas instruções passo a passo. Cada thread pode ser executado de forma independente. Se você tiver um processador de núcleo único
apenas uma thread pode ser executada por vez, e todas as threads se revezarão. Se você tiver um processador com vários núcleos, tantas threads quantos forem os núcleos
núcleos podem ser executados ao mesmo tempo. Não é possível escolher em qual núcleo uma
determinada thread será executada. Na maioria dos casos, você não conseguirá nem mesmo
saber qual núcleo uma determinada thread está usando.

Ele tem o cuidado de empacotar o conjunto certo de tarefas em uma única thread
de execução. Lembre-se dos exemplos anteriores de programação concorrente neste capítulo.

Considere a possibilidade de dividir as tarefas em <<videoGameTasksExample>> em
duas threads. As tarefas B e C podem ser agrupadas na thread 1, e a tarefa D
pode ser empacotada na thread 2.Essa divisão é mostrada em
<<figure-tasks_in_threads>>(a).

As tarefas para avaliar diferentes subexpressões em <<mathExpressionTasksExample>> também podem ser divididas em duas threads, conforme mostrado em <<figure-tasks_in_threads>> (b). Em muitos problemas, há várias maneiras razoáveis de dividir um conjunto de subtarefas em threads.

[[figure-tasks_in_threads]]
.(a) Tarefas em um videogame mostradas agrupadas em duas threads. (b) Tarefas para avaliar uma expressão matemática mostrada empacotada em duas threads. Cada thread pode ou não ser executado no mesmo núcleo que o outro.
image::task-thread-packaging.svg[scaledwidth=100%,pdfwidth=100%,width=100%]


Observe que essas figuras são exatamente iguais às figuras anteriores, exceto
que as tarefas são agrupadas como threads em vez de núcleos. Esse agrupamento 
corresponde melhor à realidade, pois podemos controlar como as tarefas são agrupadas
em threads, mas não como elas são atribuídas aos núcleos.

Em ambos os exemplos, temos duas threads. É possível que alguma outra thread tenha iniciado a execução dessas threads. Todo programa Java, simultâneo ou
sequencial, começa com uma thread. Vamos nos referir a essa thread como a thread
_main_, pois ela contém o método `main()`.

<<arraySummationPreviewExample>> e <<matrixMultiplicationPreviewExample>> usam várias tarefas idênticas,
mas essas tarefas operam em dados diferentes. Em <<arraySummationPreviewExample>>,
as duas tarefas podem ser atribuídas a duas threads que
operam em diferentes partes da matriz de entrada. A tarefa de somar
os resultados das duas threads pode ser uma thread separada ou uma
subtarefa incluída em uma das outras threads. Em
<<matrixMultiplicationPreviewExample>>, as duas tarefas podem
novamente ser atribuídas a duas threads distintas que operam em diferentes
partes diferentes da matriz de entrada _A_ para gerar as partes correspondentes
partes correspondentes da matriz de saída _C_.

Pode haver muitas maneiras de empacotar tarefas em threads. Também pode haver 
muitas maneiras de decompor os dados em pedaços menores. As melhores maneiras de 
executar essas subdivisões de tarefas ou dados dependem do problema em questão e 
da arquitetura do processador em que o programa será executado.

==== Arquitecturas de memória e concorrência

Os dois paradigmas mais importantes da programação concorrente são a passagem de mensagens e os sistemas de memória compartilhada. Cada paradigma lida com a comunicação entre as várias unidades de código executadas em paralelo de uma maneira diferente. Os sistemas de passagem de mensagens, como o MPI (Message Passing Interface), abordam esse problema enviando mensagens entre unidades de código independentes, chamadas de processos. Um processo que está executando uma tarefa pode ter de esperar até receber uma mensagem de outro processo para saber como proceder. As mensagens podem ser enviadas de um único processo para outro ou transmitidas para vários. Os sistemas de passagem de mensagens são especialmente úteis quando os processadores que executam o trabalho não compartilham memória.


Por outro lado, o sistema interno de concorrência em Java usa o paradigma de memória compartilhada.
compartilhada. Em Java, um programador
pode criar várias threads que compartilham o mesmo espaço de memória. Cada
thread é um objeto que pode executar um trabalho. Descrevemos as threads como uma como uma forma de empacotar um grupo de tarefas, e os processos são outra forma. As pessoas
usam o termo _processos_ para descrever unidades de código em execução com
memória separada e _threads_ para descrever unidades de código em execução
com memória compartilhada.

Quando você aprendeu a programar pela primeira vez, um dos maiores desafios foi provavelmente aprender a resolver um problema passo a passo. Cada linha do programa tinha de ser executada uma de cada vez, de forma lógica e
deterministica. Os seres humanos não pensam naturalmente dessa forma. Temos a tendência de pular de uma coisa para outra, fazendo inferências e suposições,
pensando em duas coisas não relacionadas ao mesmo tempo, e assim por diante. Como você sabe
agora, só é possível escrever e depurar programas por causa da maneira metódica como eles funcionam.

Você pode imaginar a execução de um programa como uma seta que aponta para uma linha de código, depois a próxima, depois a próxima e assim por diante. Podemos pensar no movimento dessa seta como a thread de execução do programa.
O código faz o trabalho real, mas a seta mantém o controle de onde a
execução do programa está no momento. O código pode mover a seta
para frente, pode fazer aritmética básica, pode decidir entre escolhas com instruções pode fazer coisas repetidamente com loops, pode pular para um método e depois voltar. Uma única thread de execução pode fazer todas essas coisas, mas sua seta não pode estar em dois lugares ao mesmo tempo. Ela não pode
dividir dois números em uma parte do programa e avaliar uma declaração `if` em outra. No entanto, há uma maneira de dividir essa thread
de execução de modo que duas ou mais threads estejam executando partes diferentes
do programa, e a próxima seção mostrará como isso é feito em
Java.

=== Sintaxe: Threads em Java

==== A classe `Thread`

O Java, como muitas linguagens de programação, inclui os recursos necessários para para empacotar tarefas e subtarefas em threads. A classe `Thread` e suas subclasses fornecem as ferramentas para criar e gerenciar threads. Por exemplo, a definição de classe a seguir permite que objetos do tipo
`ThreadedTask` sejam criados. Esse objeto pode ser executado como uma thread separada.

[source,java]
----
public class ThreadedTask extends Thread {
    // Adicionar construtor e corpo da classe
}
----

O construtor é escrito como qualquer outro construtor, mas há um método especial
`run()` em `Thread` que pode ser substituído por qualquer uma das 
suas subclasses. Esse método é o ponto de partida para a thread de execução associada a uma instância da classe. A maioria dos aplicativos Java
começa com uma única thread principal que é iniciado em um método `main()`. As threads adicionais devem começar em algum lugar, e esse lugar é o método
 `run()`. Um aplicativo Java continuará a ser executado enquanto houver pelo menos uma thread ativa. O exemplo a seguir mostra duas threads,
cada uma avaliando uma subexpressão separada, como em <<figure-tasks_in_threads>>(b).


[[threadSamplesExample]]
.Exemplos de Threads
====

Vamos criar as classes `Thread1` e `Thread2`. As threads de execução criadas por 
instâncias destas classes calculam, respetivamente, as duas subexpressões da 
<<figure-tasks_in_threads>>(b) e guardam os valores calculados.

[source, java]
[[Thread1Program]]
----
include::{programsdir}/Thread1.java[]
----


[source, java]
[[Thread2Program]]
----
include::{programsdir}/Thread2.java[]
----

O método `run()` em cada thread acima calcula uma subexpressão e salva seu 
valor. Mostramos como essas threads podem ser executados para resolver o problema 
da expressão matemática em <<mathExpressionThreadsExample>>.


====

==== Criando um objeto thread

Criar um objeto a partir de uma subclasse `Thread` é o mesmo que criar
qualquer outro objeto em Java. Por exemplo, podemos instanciar a classe `Thread1`
acima para criar um objeto chamado `thread1`.

[source,java]
----
Thread1 thread1 = new Thread1(15.1, 2.8, 7.53);
----

O uso da palavra-chave `new` para invocar o construtor cria um objeto `Thread1`,
mas não começa a executá-lo como uma nova thread. Como em todas as
outras classes, o construtor inicializa os valores dentro do novo objeto
objeto. Uma subclasse de `Thread` pode ter muitos construtores diferentes com
qualquer parâmetros que seu projetista considere apropriados.

==== Iniciando uma thread

Para iniciar a execução do objeto thread, seu método `start()` deve ser
chamado. Por exemplo, o objeto `thread1` criado acima pode ser iniciado
da seguinte forma.

[source,java]
----
thread1.start();
----

Uma vez iniciado, uma thread é executada de forma independente.  A chamada do método `start()`
chama automaticamente o método `run()` do objeto nos bastidores.
Quando uma thread precisa compartilhar dados com outra thread, ela
pode ter que esperar.

==== Aguardando por uma thread

Muitas vezes, alguma thread, principal ou não, precisa esperar por outra thread
antes de prosseguir com sua execução. O método `join()` é usado para esperar 
que uma thread termine a execução. Por exemplo, qualquer thread que executar o 
código a seguir aguardará a conclusão da `thread1`.

[source,java]
----
thread1.join();
----

A chamada `join()` é uma chamada _bloqueante_, o que significa que o código que chama
esse método aguardará até que ele retorne. Como ele pode lançar uma
`InterruptedException` verificada enquanto o código estiver aguardando, o método `join()`
é geralmente usado em um bloco `try`-`catch`. Podemos adicionar um bloco `try`-`catch` 
ao exemplo `thread1` para que possamos nos recuperar de
sermos interrompidos enquanto aguardamos a conclusão do `thread1`.

[source,java]
----
try {
	System.out.println("Aguardando pela thread 1...");
	thread1.join();
	System.out.println("Thread 1 finalizada!");
}
catch (InterruptedException e) {
	System.out.println("Thread 1 não acabou!");
}
----

Observe que a `InterruptedException` é lançada porque a thread principal
foi interrompida enquanto aguardava a conclusão da `thread1`. Se a chamada `join()`
retornar, então `thread1` deve ter terminado e informaremos o usuário.
Se uma `InterruptedException` for lançada, alguma thread externa deve ter
interrompido a thread principal, forçando-a a parar de esperar pela `thread1`.

In earlier versions of Java, there was a `stop()` method which would
stop an executing thread. Although this method still exists, it's been
deprecated and shouldn't be used because it can make a program behave
in an unexpected way.

****
<<threadMethodsExercise>>
****

[[mathExpressionThreadsExample]]
.Cálculos matemáticos com threads
====

Agora que temos a sintaxe para iniciar threads e esperar que eles terminem, podemos 
usar as threads definidos em <<threadSamplesExample>> com uma thread principal 
para criar nosso primeiro programa concorrente completo.  A thread principal na 
classe `MathExpression` cria e inicia as threads de trabalho `thread1` e `thread2` 
e aguarda sua conclusão. Quando as duas threads concluem sua execução, podemos 
solicitar a cada uma delas o valor calculado. A thread principal imprime o 
produto desses valores, que é o resultado da expressão que queremos avaliar.

[source, java]
[[MathExpressionProgram]]
----
include::{programsdir}/MathExpression.java[]
----


Queremos deixar absolutamente claro quando os threads são criados, começam
a execução e terminam. Esses detalhes são cruciais para os pontos mais finos da
programação Java simultânea. Na <<figure-tasks_in_threads>>, parece que a execução da avaliação da expressão matemática 
começa com a Thread 1, que gera a Thread 2. Embora essa figura
explique bem os conceitos básicos da decomposição de tarefas, os detalhes são mais confusos para o código Java real.


No código acima, a execução começa com o método `main()` em
`MathExpression`. Ele cria os objetos `Thread1` e `Thread2` e aguarda
que eles terminem. Em seguida, ele lê os valores dos objetos depois que 
eles pararam de ser executados. Poderíamos ter colocado o método `main()` na classe `Thread1`, omitindo totalmente a classe `MathExpression`. Desta forma isso faria com que a execução correspondesse mais de perto à <<figure-tasks_in_threads>>
mais próxima, mas tornaria as duas subclasses `Thread` menos
simétricas: a thread principal e a `thread1` executariam independentemente o código dentro da `Thread1`.
executariam independentemente o código dentro da classe `Thread1`, enquanto somente `thread2` executaria
executaria código dentro da classe `Thread2`.


[[figure-thread_execution]]
[.text-center]
.Criando, iniciando, e mesclando as threads em `MathExpression`, `Thread1`, and `Thread2`.
image::thread-lifecycle.svg[scaledwidth=75%,pdfwidth=75%,width=75%]


<<figure-thread_execution>> mostra a execução de `thread1` e
`thread2` e a thread principal. Observe que a JVM cria e inicia implicitamente
o thread principal, que cria e inicia explicitamente a `thread1` e a `thread2`.
Mesmo depois que as threads associados a `thread1` e `thread2` pararem de ser executados, 
os objetos associados a eles continuam a existir. Seus métodos e campos ainda podem ser acessados.

====

==== A interface `Runnable`

Embora seja possível criar threads em Java herdando diretamente da classe
`Thread` diretamente, a API Java permite que o programador use uma
interface em vez disso.

Como exemplo, a classe `Summer` pega uma matriz de valores `int` e os soma dentro 
de um determinado intervalo. Se várias instâncias dessa classe
forem executadas como threads separadas, cada uma delas poderá somar diferentes partes de
uma matriz.

[source, java]
----
include::{programsdir}/Summer.java[]
----


Essa classe é muito semelhante a uma classe que herda de `Thread`. Imagine
por um momento que o código que segue `Summer` é `extends Thread`
em vez de `implements Runnable`. A principal coisa que uma classe derivada de
`Thread` precisa é de um método `run()` sobrescrito. Como somente o método `run()`
é importante, os projetistas do Java forneceram uma maneira de criar uma
thread usando a interface `Runnable`. Para implementar essa interface, é necessário apenas
um método `public void run()`.

Ao criar uma nova thread, há algumas diferenças de sintaxe entre os dois estilos. A maneira conhecida de criar e executar um thread a partir de uma subclasse `Thread` é a seguinte.

[source,java]
----
Summer summer = new Summer(array, lower, upper);
summer.start();
----

Como o `Summer` não herda de `Thread`, ele não tem um método `start()`, e esse código não será compilado. Quando uma classe apenas implementa `Runnable`, ainda é necessário criar um objeto `Thread` e chamar seu método `start()`. Portanto, é necessária uma etapa extra.

[source,java]
----
Summer summer = new Summer(array, lower, upper);
Thread thread = new Thread(summer);
thread.start();
----

Essa forma alternativa de implementar a interface `Runnable` parece mais incômoda do que herdar diretamente da `Thread`, já que é necessário
instanciar um objeto `Thread` separado. Entretanto, a maioria dos desenvolvedores prefere projetar classes que implementem `Runnable` em vez de herdar de
`Thread`. Por quê? O Java só permite herança única. Se sua classe
implementar `Runnable`, ela estará livre para herdar de outra super classe 
com os recursos que você desejar.

****
<<extendingThreadExercise>>
****

[[arrayOfThreadsExample]]
.Conjunto de threads
====

Na decomposição de domínios, muitas vezes precisamos criar várias threads, todas
a partir da mesma classe. Como exemplo, considere a seguinte declaração de thread.

[source, java]
[[NumberedThreadProgram]]
----
include::{programsdir}/NumberedThread.java[]
----


Agora, suponha que desejemos criar 10 objetos de thread do tipo
`NumberedThread`, então iniciá-los e por fim esperar que sejam concluídos.

[source,java]
----
NumberedThread[] threads = new NumberedThread[10]; //<.>
for(int i = 0; i < threads.length; i++) {
    threads[i] = new NumberedThread(i); //<.>
    threads[i].start(); //<.>
}
try {
    for(int i = 0; i < threads.length; i++)
        threads[i].join(); //<.>
}
catch(InterruptedException e) {
    System.out.println("A thread didn't finish!");
}
----
<.> Primeiro, declaramos uma matriz para manter referências aos objetos `NumberedThread`. Como qualquer outro tipo, podemos criar uma matriz para armazenar objetos que
herdam de `Thread`.
<.> A primeira linha do loop `for` instancia um novo objeto `NumberedThread`, invocando o construtor que armazena a
iteração atual do loop no campo `value`. A referência a
cada objeto `NumberedThread` é armazenada na matriz. Lembre-se de que o construtor
 *não* inicia a execução de uma nova thread.
<.> A segunda linha do loop `for` faz isso.
<.> Também estamos interessados em saber quando as threads param. A chamada do método `join()`
força a thread principal a aguardar a conclusão de cada thread.

Todo o segundo loop `for` está aninhado dentro de um bloco `try`. Se a thread principal for interrompida enquanto estiver aguardando a conclusão de qualquer uma das threads terminar, uma `InterruptedException` será capturada. Como antes, avisamos o usuário
que uma thread não foi concluída. Para código com qualidade de produção, o bloco
bloco `catch` deve tratar a exceção de forma que a thread possa se recuperar e fazer um trabalho útil, mesmo que não tenha obtido o resultado esperado.

====

=== Exemplos: Concorrência e aceleração

A aceleração é uma das maiores motivações para escrever programas
concorrentes. Para entender o aumento de velocidade, vamos supor que temos um problema para
resolver. Escrevemos dois programas para resolver esse problema, um que é
sequencial e outro que é concorrente e, portanto, capaz de explorar
vários núcleos. Seja _t_~_s_~ o tempo médio de execução do
o programa sequencial e _t_~_c_~ o tempo médio de execução do programa concorrente. Para que a comparação seja
significativa, suponha que ambos os programas sejam executados no mesmo computador.
O aumento de velocidade obtido com a programação concorrente é definido como _t_~_s_~/_t_~_c_~.

A aceleração mede quanto tempo leva para o programa concorrente ser executado em relação ao programa sequencial. Idealmente, esperamos que
_t_~_c_~ < _t_~_s_~, tornando a aceleração maior que 1. No entanto,
simplesmente escrever um programa concorrente não garante que ele seja mais rápido
do que a versão sequencial.

****
<<speedupExercise>> +
<<AmdahlLawExercise>>
****

Para determinar o aumento de velocidade, precisamos medir _t_~_s_~ e _t_~_c_~. O 
tempo em um programa Java pode ser facilmente medido com
os dois métodos estáticos a seguir na classe `System`.

[source,java]
----
public static long currentTimeMillis()
public static long nanoTime()
----

O primeiro desses métodos retorna a hora atual em milissegundos (ms).
Um _millisecond_ equivale a 0,001 segundos. Esse método fornece a diferença
entre a hora atual no relógio de seu computador e a meia-noite de
1º de janeiro de 1970, horário universal coordenado (UTC). Esse ponto no tempo é
usado para muitos recursos de tempo em muitas plataformas de computador e é chamado de _epoch Unix_. O outro método retorna a hora atual em
nanossegundos (ns). Um _nanossegundo_ equivale a 0,000000001 ou 10^-9^ segundos. 
Esse método também fornece a diferença entre a hora atual e uma hora fixa, que depende do sistema e não necessariamente do _epoch_. 
O método `System.nanoTime()` pode ser usado quando você quiser uma precisão de tempo
mais fina do que milissegundos; entretanto, o nível de precisão que ele retorna é
novamente dependente do sistema. O próximo exemplo mostra como usar esses métodos
para medir o tempo de execução.

.Medindo o tempo de execução
====

Suponha que desejemos medir o tempo de execução de um trecho de código Java. Por conveniência, podemos supor que esse código esteja contido no método `work()`. O trecho de código a seguir mede o tempo de execução de
`work()`.

[source,java]
----
long start = System.currentTimeMillis();
work();
long end = System.currentTimeMillis();
System.out.println("Tempo decorrido: " + (end - start) + " ms");
----

A saída fornecerá o tempo de execução de `work()` medido em
milissegundos. Para obter o tempo de execução em nanossegundos, use o método
`System.nanoTime()` em vez de `System.currentTimeMillis()`.
====

****
<<executionVariationExercise>> +
<<threadOverheadExercise>>
****

Agora que temos as ferramentas para medir o tempo de execução, podemos medir o
aumento de velocidade. Os próximos exemplos mostram o aumento de velocidade (ou a falta dele) que podemos
podemos obter usando uma solução simultânea para alguns problemas simples.

.Acelerando o cálculo matemático
====

Lembre-se do programa concorrente em <<mathExpressionThreadsExample>> para avaliar uma expressão matemática simples. Esse programa
usa duas threads. Executamos esse programa multithread em um computador iMac
com um Intel Core 2 Duo rodando a 2,16 Ghz. O tempo de execução
O tempo de execução foi medido em 1.660.000 nanossegundos. Também escrevemos um programa
programa sequencial simples para avaliar a mesma expressão. Foram necessários 4.100
nanossegundos para executar esse programa no mesmo computador. Ao inserir
esses valores para _t_~_c_~ e _t_~_s_~, podemos encontrar
a aceleração.

//[stem]
//++++
//\mbox{speedup}=\frac{t_s}{t_c} = \frac{4,100}{1,660,000} = 0.00246
//++++

[.text-center]
image::speedup.svg[scaledwidth=45%,pdfwidth=45%,width=45%]

Essa aceleração é muito menor que 1. Embora esse resultado possa ser surpreendente,
o programa concorrente com duas threads é executado mais lentamente do que o programa 
sequencial. Nesse exemplo, o custo de criar, executar e
processar as threads supera os benefícios do cálculo simultâneo em dois
núcleos.
====

****
<<speedupLimitationsExercise>>
****

[[arraySummationExample]]
.Somatório de matrizes
====

Em <<arraySummationPreviewExample>>, apresentamos o
problema de aplicar uma função a cada valor em uma matriz e depois
somar os resultados. Digamos que queiramos aplicar a função seno
a cada valor. Para resolver esse problema de forma concorrente, particionamos 
a matriz uniformemente entre várias threads, usando a estratégia de decomposição de domínio.
Cada thread encontra a soma dos senos dos valores em sua
parte da matriz. Um fator que determina se conseguimos ou não
velocidade é a complexidade da função, nesse caso o seno, que aplicamos.
aplicamos. Embora possamos obter um aumento de velocidade com o seno, uma função mais simples
como dobrar o valor pode não gerar trabalho suficiente para justificar a
sobrecarga do uso de threads.

Criamos a classe `SumThread` cujo método `run()` soma os senos dos
elementos da matriz em sua partição atribuída.

[source, java]
----
include::{programsdir}/SumThread.java[lines=1..15]
----
<.> Primeiro, configuramos todos os campos de que a classe precisará.
<.> Observe que cada objeto `SumThread` terá sua própria referência à matriz de dados.
<.> Fixamos o tamanho da matriz em 1.000.000 e o número de threads em 8, mas esses valores
podem ser facilmente alterados ou lidos como entrada.
<.> Em seu construtor, um `SumThread` recebe uma referência à matriz de dados
e os limites inferior e superior de sua partição. Como a maioria dos
intervalos que discutimos, o limite inferior é inclusivo, embora o limite superior
seja exclusivo.

[source, java]
----
include::{programsdir}/SumThread.java[lines=17..22]
----
<.> No loop `for` do método `run()`, a `SumThread` encontra o seno
de cada número em sua partição da matriz e adiciona esse valor à sua
soma. 
<.> O método `getSum()` é um acessório que permite que a soma em execução seja
seja recuperada.

[source, java]
----
include::{programsdir}/SumThread.java[lines=24..40]
----
<.> O método `main()` começa instanciando a matriz.
<.> Ele o preenche com valores aleatórios.
<.> Em seguida, cada thread é criado passando uma referência para o vetor e os limites 
inferior e superior que marcam a partição da thread na matriz. Se o
processo que usa o comprimento da matriz e o número de threads para determinar
os limites superior e inferior não fizer sentido, consulte
<<Concurrency: Arrays>> que descreve a divisão justa do trabalho
para as threads. Se o comprimento da matriz não for divisível pelo número de
threads, a divisão simples não será suficiente.
<.> Depois que cada thread é criada, seu método `start()` é chamado.

[source, java]
----
include::{programsdir}/SumThread.java[lines=42..54]
----
<.> Depois que as threads começam a trabalhar, a thread principal cria seu próprio
total em execução.
<.> Ele itera através de cada thread esperando que seja concluído. 
<.> Quando cada thread é concluída, seu valor é adicionado ao
ao total em execução.
<.> Finalmente, a soma é impressa.
<.> Se a thread principal for interrompida enquanto estiver aguardando a conclusão de uma
thread, o rastreamento da pilha será impresso. 
====

****
<<parallelAudioProcessingExercise>> +
<<arraySummingSpeedupExercise>> +
<<treeSummationExercise>>
****

[[matrixMultiplicationExample]]
.Multiplicação de matrizes
====

Em <<matrixMultiplicationPreviewExample>>, discutimos a
a importância das operações de matriz em muitos aplicativos. Agora que conhecemos
a sintaxe Java necessária, podemos escrever um programa concorrente para multiplicar
duas matrizes quadradas _A_ e _B_ e calcular a matriz
resultante _C_. Se essas matrizes tiverem _n_
linhas e _n_ colunas, o valor na _i_^ésima^
linha e _j_^^ coluna de _C_ é

//[stem]
//++++
//C_{ij} = \sum_{k = 1}^n A_{ik}B_{kj} = A_{i1}B_{1j} + A_{i2}B_{2j} + \ldots + A_{in}B_{nj}
//++++

[.text-center]
image::matrixValue.svg[scaledwidth=55%,pdfwidth=55%,width=55%]

Em Java, é natural armazenarmos as matrizes como matrizes bidimensionais.
Para fazer essa multiplicação sequencialmente, a abordagem mais simples usa três
loops `for` aninhados. O código abaixo é uma tradução direta da 
notação matemática, mas temos de ter cuidado com a contagem.
Observe que a notação matemática geralmente usa letras maiúsculas para
para representar matrizes, embora a convenção Java seja iniciar todos os nomes de variáveis
com letras minúsculas.

[source,java]
----
for(int i = 0; i < c.length; i++)
    for(int j = 0; j < c[i].length; j++)
        for(int k = 0; k < b.length; k++)
            c[i][j] += a[i][k] * b[k][j];
----

A primeira etapa para criar uma solução concorrente para esse problema é
criar uma subclasse `Thread` que fará alguma parte da 
multiplicação da matriz. Abaixo está a classe `MatrixThread` que calculará um 
número de linhas na matriz de resposta `c`.

[source, java]
[[MatrixThreadProgram]]
----
include::{programsdir}/MatrixThread.java[]
----
<.> O construtor de `MatrixThread` armazena referências às matrizes
correspondentes às matrizes _A_, _B_ e _C_, bem como os limites inferior e superior das linhas de
_C_ a serem computadas. 
<.> O corpo do método `run()` é idêntico ao da solução sequencial, exceto pelo fato de que seu `loop` mais externo é executado somente de
`lower` a `upper` em vez de percorrer todas as linhas do resultado.
É fundamental que a cada thread seja atribuído um conjunto de linhas que não se
se sobreponha às linhas que outra thread possui. Não só o fato de 
várias threads calcularem a mesma linha seria ineficiente, mas muito provavelmente levaria
a um resultado incorreto, como veremos em
<<ch14-synchronization#ch14-synchronization>>.

O código cliente a seguir usa uma matriz de objetos `MatrixThread` para
realizar uma multiplicação de matriz. Supomos que uma constante `int` denominada
`THREADS` tenha sido definida, o que dá o número de threads que queremos criar. 

[source,java]
----
MatrixThread[] threads = new MatrixThread[THREADS];
int quotient = c.length / THREADS;
int remainder = c.length % THREADS;
int start = 0;
for(int i = 0; i < THREADS; i++) {
    int rows = quotient;
    if(i < remainder)
        rows++;
    threads[i] = new MatrixThread(a, b, c, start, start + rows); //<.>
    threads[i].start(); //<.>
    start += rows;
}
try {
    for(int i = 0; i < THREADS; i++) //<.>
        threads[i].join();
}
catch(InterruptedException e) {
    e.printStackTrace();
}
----
<.> Fazemos um `loop` pela matriz, criando um objeto `MatrixThread` para cada
posição. Como no exemplo anterior, usamos a abordagem descrita em
<<Concurrency: Arrays>> para alocar linhas para cada thread de forma justa.
Cada novo objeto `MatrixThread` recebe uma referência a cada uma das três
matrizes, bem como uma linha inicial inclusiva e uma linha final exclusiva.
<.> Depois que os objetos `MatrixThread` são criados, começamos a executá-los com a próxima linha de código.
<.> Em seguida, há um `loop` `for` familiar com as chamadas `join()` 
que forçam a thread principal a esperar que as outras threads terminem.

Presumivelmente,
o código após esse trecho imprimirá os valores da matriz de resultados
ou a usará para outros cálculos. Se não tivermos usado as chamadas `join()`
para garantir que as threads tenham terminado, poderíamos imprimir uma matriz de resultados que foi preenchida apenas parcialmente.

Concluímos o código da multiplicação de matrizes com threads e o executamos
em um computador iMac com um Intel Core 2 Duo rodando a 2,16 Ghz. O programa
foi executado para matrizes de diferentes tamanhos (_n_ × _n_). Para cada tamanho, os 
tempos de execução sequencial e concorrente em segundos
e o tempo de execucação correspondente estão listados na tabela a seguir.

[.center%autowidth%header,cols="4*<",]
|=======================================================================
|Size (_n_) |_t_~_s_~ (s) |_t_~_c_~ (s)
|Speedup
|100 |0.013 |0.9 |0.014

|500 |1.75 |4.5 |0.39

|1,000 |15.6 |10.7 |1.45^*^
|=======================================================================

Somente com matrizes de 1.000 × 1.000 observamos um melhor
desempenho ao usar duas threads. Nesse caso, obtivemos um aumento de velocidade
de 1,45, marcado com um asterisco. Nos outros dois casos, o desempenho piorou.
====

****
<<parallelPiApproximationExercise>> +
<<matrixSpeedupExercise>>
****

=== Conteitos: Agendamento de thread

Agora que vimos como várias threads podem ser usadas juntas, 
várias perguntas surgem: Quem decide quando
essas threads são executadas? Como o tempo do processador é compartilhado 
entre as threads? Podemos fazer alguma suposição sobre a ordem de execução 
das threads? Podemos afetar essa ordem?

Essas perguntas se concentram no agendamento de threads. Como diferentes sistemas 
concorrente lidam com o agendamento de forma diferente, descreveremos apenas o agendamento
em Java. Embora a programação sequencial tenha tudo a ver com o controle preciso
sobre o que acontece *depois*, a concorrência tira grande parte desse controle do 
programador. Quando os threads são agendados e em qual processador eles são executados, isso 
é feito por uma combinação da JVM e do sistema operacional. Com as
JVMs normais, não há uma maneira explícita de acessar o agendamento e alterá-lo a seu
seu agrado.

Obviamente, há várias maneiras implícitas pelas quais um programador pode manipular a
a programação. Em Java, como em várias outras linguagens
e sistemas de programação, as threads têm _prioridades_. As threads de prioridade mais 
alta são executadas com mais frequência do que as de prioridade mais baixa. Algumas 
threads estão executando operações de missão crítica que devem ser executadas o mais 
rápido possível, e algumas threads estão apenas realizando tarefas periódicas 
em segundo plano. Um programador pode definir as prioridades das threads de acordo com essas prioridades.

A definição de prioridades oferece apenas uma maneira muito geral de controlar 
qual thread será executada. As próprias threads podem ter informações mais específicas 
sobre quando precisarão ou não de tempo de processador. A thread pode precisar esperar 
por um evento específico e não precisará ser executada
até lá. O Java permite que as threads interajam com o agendador por meio dos 
métodos `Thread.sleep()` e `Thread.yield()`, que discutiremos em <<Syntax: Thread states>> e 
por meio do método `wait()`, que discutiremos em <<ch14-synchronization#ch14-synchronization>>.

==== Não determinismo

Em Java, o mapeamento de uma thread dentro da JVM para uma thread no sistema operacional
varia. Algumas implementações dão a cada thread Java uma thread do sistema operacional, outras
colocam todas as threads Java em uma única thread do sistema operacional (com o efeito 
colateral de impedir a execução paralela), e algumas permitem a possibilidade de alterar
qual thread do sistema operacional uma thread Java usa. Assim, o desempenho e, em alguns 
casos, a correção de seu programa podem variar, dependendo do sistema que você estiver executando.
Esse é, mais uma vez, um daqueles momentos em que o Java
é independente de plataforma... mas não totalmente.

Infelizmente, a situação é ainda mais complicada. Tornar as threads
parte de seu programa significa que o mesmo programa pode ser executado de forma diferente
no *mesmo* sistema. A JVM e o sistema operacional precisam cooperar para agendar as threads
e ambos os programas são montanhas complexas de código que tentam equilibrar muitos fatores. 
Se você criar três threads, não há garantia
que o primeiro será executado primeiro, o segundo segundo e o terceiro terceiro,
mesmo que isso aconteça nas primeiras 10 vezes em que você executar o programa. O 
<<executionOrderExercise>> mostra que o padrão de execução das threads pode variar muito.

****
<<executionOrderExercise>>
****

Em todos os programas anteriores a este capítulo, a mesma sequência de entrada
sempre produziria a mesma sequência de saída. Talvez o maior
obstáculo criado por esse não determinismo seja o fato de os programadores 
terem de mudar seu paradigma consideravelmente. O processador pode alternar 
entre execuções de de threads a qualquer momento, mesmo no meio das operações. Todas as possíveis
intercalações de execução de thread pode surgir em algum momento. A menos 
que você tenha certeza de que seu programa se comporta adequadamente em todos 
eles, talvez você nunca conseguirá depurar seu código completamente. O que é tão insidioso nos
bugs não determinísticos é que eles podem ocorrer raramente e ser quase
impossíveis de reproduzir. Neste capítulo, apresentamos como criar e executar 
threads, mas fazer com que essas threads interajam adequadamente é um
problema importante que abordaremos nos capítulos seguintes.

Depois dessas terríveis palavras de advertência, gostaríamos de lembrá-lo de que
o não determinismo não é em si uma coisa ruim. Muitos aplicativos com threads
com muitas entradas e saídas, como os servidores de aplicação, necessariamente
existem em um mundo não determinístico. Para esses programas, muitas diferentes 
sequências de threads em execução podem ser perfeitamente válidas. Cada programa 
individual pode ter uma definição diferente de correção. Por exemplo, se um servidor 
do mercado de ações receber duas solicitações para comprar a última ação de uma 
determinada empresa quase ao mesmo tempo de duas threads correspondentes a dois 
clientes diferentes, pode ser correto que qualquer um deles
obtenha a última ação. No entanto, nunca seria correto que *ambos* a recebam.

==== Votação

Até agora, o único mecanismo que introduzimos para coordenar diferentes
threads é usar o método `join()` para aguardar o término de uma thread.
Outra técnica é _polling_, ou _busy waiting_. A ideia é continuar
verificando o estado de uma thread até que ela mude.

Há vários problemas com essa abordagem. O primeiro é que ela
desperdiça ciclos da CPU. Os ciclos gastos pela thread em espera continuamente
poderiam ter sido usados de forma produtiva por alguma outra thread no sistema. O 
segundo problema é que precisamos ter certeza de que o estado da thread que 
estamos esperando não voltará ao estado original ou para algum outro estado. Devido 
à imprevisibilidade do agendamento,
não há garantia de que a thread em espera lerá o estado da outra thread quando 
ela tiver o valor correto.

Mencionamos a votação em parte porque ela tem uma importância histórica para a
programação paralela, em parte porque pode ser útil na solução de alguns
problemas deste capítulo e, em parte, porque queremos que você entenda
os motivos pelos quais precisamos de técnicas melhores para a comunicação entre threads.

****
<<pollingArraySumExercise>>
****

=== Sintaxe: Estados da thread

Uma ferramenta Java amplamente utilizada para manipular o agendamento é o método `Thread.sleep()`. Esse método pode ser chamado sempre que você quiser que uma
thread não faça nada por um determinado período de tempo. Até que o temporizador `sleep`
expire, a thread não será agendada para nenhum tempo de CPU, a menos que seja
interrompida. Para fazer uma thread de execução dormir, chame `Thread.sleep()`
nessa thread de execução com um número de milissegundos como parâmetro. Por exemplo, chamar `Thread.sleep(2000)` fará com que a
thread chamada dormirá por dois segundos completos.

Outra ferramenta útil é o método `Thread.yield()`. Ele abre mão do uso da
CPU para que a próxima thread em espera possa ser executada. Para usá-lo, uma thread
chama `Thread.yield()`. Esse método é útil na prática, mas
de acordo com a documentação oficial, a JVM não *tem* que fazer nada quando 
um `Thread.yield()` é executado. A especificação Java não exige uma implementação 
específica. Uma JVM poderia ignorar uma chamada
chamada `Thread.yield()` completamente, mas a maioria das JVMs passará para a 
próxima thread no cronograma.

****
<<sleepAndYieldMethodsExercise>> +
<<sleepTimerExercise>>
****

[[figure-thread_states]]
[.text-center]
.Estados e transições da thread.
image::thread-states.svg[scaledwidth=80%,pdfwidth=80%,width=80%]


<<figure-thread_states>> mostra o ciclo de vida de uma thread. A
thread começa sua vida no estado `New Thread`, depois que o construtor 
é chamado. Quando o método `start()` é chamado, a thread começa a ser executada
e faz a transição para o estado `Runnable. Ser executável não significa
necessariamente que a thread está sendo executada em um determinado momento, mas
que ela está pronta para ser executada a qualquer momento. Quando estiver no 
estado `Runnable`, uma thread pode chamar `Thread.yield()`, deixando de usar o processador,
mas ainda permanecerá `Runnable`.

No entanto, se uma thread for dormir com uma chamada `Thread.sleep()`, aguardará
para que uma condição seja verdadeira usando uma chamada `wait()` ou executar uma operação de
de E/S bloqueante, a thread fará a transição para o estado `Not Runnable`. As 
threads não executáveis não podem ser agendadas para o tempo de processador até que 
acordem, terminem de esperar ou concluam sua E/S. O estado final é
`Terminated`. Uma thread se torna terminada quando seu método `run()`
termina. Uma thread terminada não pode se tornar executável novamente e 
não é mais uma thread de execução separado.

Qualquer objeto com um tipo que seja uma subclasse de `Thread` pode informar seu
estado atual usando o método `getState()`. Esse método retorna um tipo _enum_, cujo 
valor deve vir de uma lista fixa de objetos constantes. Esses objetos são `Thread.State.NEW`, 
`Thread.State.RUNNABLE`, `Thread.State.BLOCKED`, `Thread.State.WAITING`,
`Thread.State.TIMED_WAITING` e `Thread.State.TERMINATED`. Embora os outros sejam 
autoexplicativos, agrupamos o `Thread.State.BLOCKED`,
`Thread.State.WAITING` e `Thread.State.TIMED_WAITING` no estado `Not Runnable`, já que 
a distinção entre os três não é importante para nós.

As threads também têm prioridades em Java. Quando um objeto que é uma subclasse
de `Thread` é criado em Java, sua prioridade é inicialmente a mesma da thread que o cria. 
Normalmente, essa prioridade é `Thread.NORM_PRIORITY`, mas há alguns casos especiais em que é uma
boa ideia aumentar ou diminuir essa prioridade. Evite alterar as prioridades de thread
porque isso aumenta a dependência da plataforma e porque os efeitos nem sempre são previsíveis. Esteja 
ciente de que as prioridades existem, mas não as use a menos que você tenha um bom motivo.

.Marcha militar
====

Vamos aplicar as ideias discutidas acima a um exemplo leve. Você
talvez esteja familiarizado com o som de soldados marchando: “`Esquerda, esquerda, esquerda,
direita, esquerda!`” Podemos criar uma thread que imprima "Esquerda" e outra que imprima "Direita".
Podemos combinar as duas para imprimir a sequência correta
para marchar e repetir tudo 10 vezes para que possamos
ver com que precisão podemos posicionar as palavras. Queremos usar as ferramentas de agendamento
discutidas acima para obter o tempo correto. Vamos tentar `Thread.sleep()`
first.

[source, java]
[[LeftThreadProgram]]
----
include::{programsdir}/LeftThread.java[]
----
<.> Dentro do loop `for`, essa thread imprime `Left` três vezes.
<.> Em seguida, ele aguarda 10 milissegundos.
<.> Finalmente, ele imprime `Esquerda` novamente e repete o loop.

[source, java]
[[RightThreadProgram]]
----
include::{programsdir}/RightThread.java[]
----
<.> Essa thread aguarda 5 milissegundos para ser sincronizada.
<.> Dentro de seu loop `for`, ele imprime `Right`.
<.> Em seguida, ela aguarda 10 milissegundos e repete o loop.

O programa de driver abaixo cria uma thread para cada uma dessas
classes e, em seguida, as inicia. Se você executar esse programa, verá 10
linhas de `Left Left Left Right Left`, mas há alguns problemas.

[source, java]
[[MilitaryMarchingProgram]]
----
include::{programsdir}/MilitaryMarching.java[]
----


O primeiro problema é que temos que esperar algum tempo entre as
chamadas. Poderíamos encurtar as chamadas `Thread.sleep()`, mas há limites
na resolução do cronômetro. O maior problema é que as duas
threads podem, às vezes, ficar fora de sincronia. Se você executar o programa muitas
vezes, você poderá ver um `Right` fora do lugar de vez em quando. Se você
aumentar as repetições dos loops `for` para um número maior, os
erros se tornarão mais prováveis. O fato de você ver ou não os erros depende um 
depende do sistema. Podemos tentar `Thread.yield()` em vez de `Thread.sleep()`.

[source, java]
[[LeftYieldThreadProgram]]
----
include::{programsdir}/LeftYieldThread.java[]
----


[source, java]
[[RightYieldThreadProgram]]
----
include::{programsdir}/RightYieldThread.java[]
----


Essas novas versões das duas classes basicamente substituíram as chamadas para
`Thread.sleep()` por chamadas para `Thread.yield()`. Sem a necessidade de
tratamento de exceções, o código é mais simples, mas trocamos um conjunto de
problemas por outro. Se houver outras threads operando na mesma aplicação, eles 
serão agendadas de forma a interferir no padrão de rendimento. Se você estiver 
executando esse código em uma máquina
com um único processador e um único núcleo, você terá uma boa chance de
ver algo que corresponda ao resultado esperado. No entanto, se estiver executando 
em vários núcleos, tudo ficará confuso. É provável que
a `LeftYieldThread` esteja sendo executada em um processador com a
`RightYieldThread` em outro. Nesse caso, nenhuma delas tem concorrência
para ceder.


Por fim, vamos dar uma olhada em uma solução de pesquisa de opinião que ainda não é suficiente. Para fazer isso, precisamos de variáveis de estado dentro de cada classe para
para saber se ela foi concluída ou não. Cada thread precisa de uma referência
para a outra thread para fazer consultas, e o programa controlador deve ser atualizado para adicioná-las antes de iniciar as threads.

[source, java]
[[LeftPollingThreadProgram]]
----
include::{programsdir}/LeftPollingThread.java[]
----


[source, java]
[[RightPollingThreadProgram]]
----
include::{programsdir}/RightPollingThread.java[]
----


Seja com um único núcleo ou com vários núcleos, essa solução sempre fornecerá 
a saída correta. Ou deveria. Os especialistas em Java apontarão que estamos
violando um aspecto técnico do modelo de memória Java. Como não estamos 
usando ferramentas de sincronização, não temos garantia de que a alteração da variável
`done` será sequer *visível* de uma thread para outra. Na prática, esse 
problema raramente o afetará, mas, por segurança, ambas as variáveis
as variáveis `done` devem ser declaradas com a palavra-chave `volatile`.
Essa palavra-chave faz com que o Java saiba que o valor pode ser acessado 
a qualquer momento por threads arbitrárias.


Outro problema é que não há *nenhuma* execução paralela. Cada thread deve esperar
para que o outro seja concluído.É claro que esse problema não se beneficia de
paralelismo, mas aplicar essa solução a problemas que podem se beneficiar do 
paralelismo pode causar problemas de desempenho. Cada thread
desperdiça tempo ocupado esperando em um loop `while` que o outro seja concluído,
consumindo ciclos de CPU enquanto faz isso. Você perceberá que o código
ainda deve ser escrito com cuidado. Cada thread deve definir o valor`done` da 
outra thread para `false`. Se as threads fossem responsáveis por definir seus
próprios valores `done` para `false`, uma thread poderia imprimir suas 
informações e voltar para o topo da tabela `for` antes que a outra thread 
tivesse redefinido seu próprio `done` para `false`.

Em resumo, a coordenação de duas ou mais threads é um problema difícil.
Nenhuma das soluções que apresentamos aqui é totalmente aceitável. Nós 
apresentamos ferramentas melhores para coordenação e sincronização em 
<<ch14-synchronization#ch14-synchronization>>.

====

=== Solução: Vírus mortal

Finally, we give the solution to the deadly virus problem. By this
point, the threaded part of this problem should not seem very difficult.
It's simpler than some of the examples, such as matrix multiplication.
We begin with the worker class `FactorThread` that can be spawned as a
thread.

.Thread class used to find the sum of the two factors of a large odd composite.
[source, java]
[[FactorThreadProgram]]
----
include::{programsdir}/FactorThread.java[]
----

The constructor for `FactorThread` takes an upper and lower bound,
similar to `MatrixThread`. Once a `FactorThread` object has those
bounds, it can search between them. The number to factor is stored in
the `Factor` class. If any value divides that number evenly, it must be
one of the factors, making the other factor easy to find, sum, and print
out. We have to add a couple of extra lines of code to make sure that we
only search the odd numbers in the range. This solution is tuned for
efficiency for this specific security problem. A program to find general
prime factors would have to be more flexible. Next, let's examine the
driver program `Factor`.

.Driver class which creates threads to lower the average search time for the factors of a large odd composite.
[source, java]
[[FactorProgram]]
----
include::{programsdir}/Factor.java[]
----
<.> Static constants hold both the number to be factored and the number of
threads.
<.> In the `main()` method, we create an array of threads for
storage.
<.> Then, we create and start each `FactorThread` object, assigning upper and
lower bounds at the same time, using the standard technique from
<<Concurrency: Arrays>> to divide the work fairly. Because we
know the number we're dividing isn't even, we start with 3. By only
going up to the square root of the number, we know that we will only
find the smaller of the two factors. In that way we can avoid having one
thread find the smaller while another is finds the larger.
<.> Afterward, we have the usual `join()` calls to make sure that all the
threads are done. In this problem, these calls are unnecessary. One
thread will print out the correct security code, and the others will
search fruitlessly. If the program went on to do other work, we might
need to let the other threads finish or even interrupt them. Don't
forget `join()` calls since they're usually very important.

=== Summary

In this chapter we've explored
two strategies to obtain a concurrent solution to programming problems.
One strategy, task decomposition, splits a task into two or more
subtasks. These subtasks can then be packaged as Java threads and
executed on different cores of a multicore processor. Another strategy,
domain decomposition, partitions input data into smaller chunks and
allows different threads to work concurrently on each chunk of data.

A concurrent solution to a programming problem can sometimes execute more quickly
than a sequential solution. Speedup measure how effective a concurrent
solution is at exploiting the architecture of a multicore processor.
Note that not all concurrent programs lead to speedup as some run slower
than their sequential counterparts. Writing a concurrent program is a
challenge that forces us to divide up work and data in a
way that best exploits the available processors and OS.

Java provides a rich set of primitives and syntactic elements to write
concurrent programs, but only a few of these were introduced in this
chapter. Subsequent chapters give additional tools to code more complex
concurrent programs.

=== Exercises
*Conceptual Problems*

.  [[threadMethodsExercise]] The `start()`, `run()`, and `join()`
methods are essential parts of the process of using threads in Java.
Explain the purpose of each method.
.  [[extendingThreadExercise]] What's the difference between
extending the `Thread` class and implementing the `Runnable` interface?
When should you use one over the other?
.  [[sleepAndYieldMethodsExercise]] How do the `Thread.sleep()` method and
the `Thread.yield()` method each affect thread scheduling?
.  [[mathExpressionTimingExercise]] Consider the expression in
<<mathExpressionTasksExample>>. Suppose that the multiply and
exponentiation operations require 1 and 10 time units, respectively.
Compute the number of time units required to evaluate the expression as
in <<figure-math_evaluation>>(a) and (b).
.  [[quad-coreExercise]] Suppose that a computer has one
quad-core processor. Can the tasks in <<videoGameTasksExample>> and <<mathExpressionTasksExample>> be further subdivided to
improve performance on four cores? Why or why not?
.  [[speedupExercise]] Consider the definition of speedup from
<<Examples: Concurrency and speedup>>. Let's assume you have a
job 1,000,000 units in size. A thread can process 10,000 units of work
every second. It takes an additional 100 units of work to create a new
thread. What's the speedup if you have a dual-core processor and create
2 threads? What if you have a quad-core processor and create 4 threads?
Or an 8-core processor and create 8 threads? You may assume that a
thread does not need to communicate after it's been created.
.  [[speedupLimitationsExercise]] In which situations can speedup be
smaller than the number of processors? Is it ever possible for speedup
to be greater than the number of processors?
.  [[AmdahlLawExercise]] Amdahl's Law is a mathematical description of
the maximum amount you can improve a system by only improving a part of
it. One form of it states that the maximum speedup attainable in a
parallel program is 1/(1 - _P_) where _P_
is the fraction of the program which can be parallelized to an arbitrary
degree. If 30% of the work in a program can be fully parallelized but
the rest is completely serial, what's the speedup with two processors? Four?
Eight? What implications does Amdahl's Law have?
.  [[minimumTimeForTasksExercise]] Consider the following table of
tasks:
+
[.center%autowidth%header,cols="<.^,^.^,^.^,<.^",]
|===========================================
|Task |Time |Concurrency |Dependency
|Washing Dishes |30 |3 |
|Cooking Dinner |45 |3 |Washing Dishes
|Cleaning Bedroom |10 |2 |
|Cleaning Bathroom |30 |2 |
|Doing Homework |30 |1 |Cleaning Bedroom
|===========================================
+
In this table, the *Time* column gives the number of minutes a task
takes to perform with a single person, the *Concurrency* column gives
the maximum number of people who can be assigned to a task, and the
*Dependency* column shows which tasks can't start until other tasks
have been finished. Assume that people assigned to a given task can
perfectly divide the work. In other words, the time a task takes is the
single person time divided by the number of people assigned. What's the
minimum amount of time needed to perform all tasks with only a single
person? What is the minimum amount of time needed to perform all tasks
with an unlimited number of people? What's the smallest number of
people needed to achieve this minimum time?
. [[sharedThreadVariableExercise]] Consider the following code snippet.
+
[source,java]
----
x = 13;
x = x * 10;
----
+
Consider this snippet as well.
+
[source,java]
----
x = 7;
x = x + x;
----
+
If we assume that these two snippets of code are running on separate
threads but that `x` is a shared variable, what are the possible values
`x` could have after both snippets have run? Remember that the execution
of these snippets can be interleaved in *any* way.

*Programming Practice*

. [[pollingArraySumExercise]] Re-implement the array summing problem from
<<arraySummationExample>> using polling instead of `join()`
calls. Your program should not use a single call to `join()`. Polling is
not an ideal way to solve this problem, but it's worth thinking about the technique.
. [[parallelAudioProcessingExercise]] Composers often work with multiple tracks
of music. One track might contain solo vocals, another drums, a third
one violins, and so on. After recording the entire take, a mix engineer
might want to apply special effects such as an echo to one or more
tracks.
+
To understand how to add echo to a track, suppose that the track
consists of a list of audio samples. Each sample in a mono (not stereo)
track can be stored as a `double` in an array. To create an echo effect,
we combine the current value of an audio sample with a sample from a
fixed time earlier. This time is called the _delay_ parameter. Varying
the delay can produce long and short echoes.
+
If the samples are stored in array `in` and the delay parameter is
stored in variable `delay` (measured in number of samples), the following code snippet can be used to
create array `out` which contains the sound with an echo.
+
[source,java]
----
double[] out = new double[in.length + delay];
// Sound before echo starts
for(int i = 0; i < delay; i++)
    out[i] = in[i];
// Sound with echo
for(int i = delay; i < in.length; i++)
    out[i] = a*in[i] + b*in[i - delay];
// Echo after sound is over
for(int i = in.length; i < out.length; i++)
    out[i] = b*in[i - delay];
----
+
Parameters `a` and `b` are used to control the nature of the echo. When
`a` is `1` and `b` is `0`, there is no echo. When `a` is `0` and `b` is
`1`, there is no mixing. Audio engineers will control the values of `a`
and `b` to create the desired echo effect.
+
Write a threaded program that computes the values in `out` in parallel
for an arbitrary number of threads.
. [[sleepTimerExercise]] Write a program which takes a number of
minutes and seconds as input. In this program, implement a timer using
`Thread.sleep()` calls. Each second, print the remaining time to the
screen. How accurate is your timer?
. [[parallelPiApproximationExercise]] As you know,
_π_ ≈ 3.1416. A more precise value can be found by writing a program which
approximates the area of a circle. The area of a circle can be
approximated by summing up the area of rectangles filling curve of the
arc of the circle. As the width of the rectangle goes to zero, the
approximation becomes closer and closer to the true area. If a circle with radius
_r_ is centered at the origin, its height _y_ at a particular  
distance _x_ is given by the following formula. 
//[stem]
//++++
//y = \sqrt{r^2 - x^2}
//++++
+
[.text-center]
image::circleHeight.svg[scaledwidth=15%,pdfwidth=15%,width=15%]
+
Write a parallel implementation of this problem which divides up
portions of the arc of the circle among several threads and then sums
the results after they all finish. By setting _r_ = 2, you
need only sum one quadrant of a circle to get _π_. You'll need to
use a very small rectangle width to get an accurate answer.
When your program finishes running, you can compare your value against
`Math.PI` for accuracy.

*Experiments*

. [[executionVariationExercise]] Use the `currentTimeMillis()` method
to measure the time taken to execute a relatively long-running piece of
Java code you've written. Execute your program several times and
compare the execution time you obtain during different executions. Why
do you think the execution times are different?
. [[threadOverheadExercise]] Thread creation overhead is an
important consideration in writing efficient parallel programs. Write a
program which creates a large number of threads which do nothing. Test
how long it takes to create and join various numbers of threads. See if
you can determine how long a single thread creation operation takes on
your system, on average.
. [[matrixSpeedupExercise]] Create serial and concurrent
implementations of matrix multiplication like those described in
<<matrixMultiplicationExample>>.
..  Experiment with different matrix sizes and thread counts to see how
the speedup performance changes. If possible, run your tests on machines
with different numbers of cores or processors.
..  Given a machine with _k_ > 1 cores, what is the maximum
speedup you can expect to obtain?
. [[executionOrderExercise]] Repeatedly run the code in
<<arrayOfThreadsExample>> which creates several
`NumberedThread` objects. Can you discover any patterns in the order
that the threads print? Add a loop and some additional instrumentation
to the `NumberedThread` class which will allow you to measure how long
each thread runs before the next thread has a turn.
. [[arraySummingSpeedupExercise]] Create serial and parallel implementations of
the array summing problem solved in <<arraySummationExample>>.
Experiment with different array sizes and thread counts to see how
performance changes. How does the speedup differ from matrix multiply?
What happens if you simply sum the numbers instead of taking the sine
first?
. [[treeSummationExercise]] The solution to the array summing problem in
<<arraySummationExample>> seems to use concurrency
half-heartedly. After all the threads have computed their sums, the main
thread sums up the partial sums sequentially.
+
An alternative approach is to sum up the partial sums concurrently. Once
a thread has computed the sum of the sines of each partition, the sums
of each pair of neighboring partitions should be merged into a single
sum. The process can be repeated until the final sum has been computed.
At each step, half of the remaining threads will have nothing left to do
and will stop. The pattern of summing is like a tree which starts with
_k_ threads working at the first stage,
_k_/2 working at the second stage,
_k_/4 working at the third, and so on, until a
single thread completes the summing process.
+
[[figure-tree_summation]]
.Example of concurrent tree-style summation with 8 threads.
image::treesummation.svg[scaledwidth=100%,pdfwidth=100%,width=100%]

+
Update the `run()` method in the `SumThread` class so that it adds its
assigned elements as before and then adds its neighbor's sum to its own.
To do so, it must use the `join()` method to wait for the neighboring
thread. It should perform this process repeatedly. After summing their
own values, each even numbered thread should add in the partial sum from
its neighbor. At the next step, each thread with a number divisible by 4
should add the partial sum from its neighbor. At the next step, each
thread with a number divisible by 8 should add the partial sum from its
neighbor, and so on. Thread 0 will perform the final summation.
Consequently, the main thread only needs to wait for thread 0. So that
each thread can wait for other threads, the `threads` array will need to
be a static field. <<figure-tree_summation>> illustrates this
process.
+
Once you've implemented this design, test it against the original
`SumThread` class to see how it performs. Restrict the number of threads
you create to a power of 2 to make it easier to determine which threads
wait and which threads terminate.
